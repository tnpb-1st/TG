{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eXHTtgcufYj8",
    "outputId": "b7d82a74-78bc-4431-93a1-d6648763ed83"
   },
   "outputs": [],
   "source": [
    "# !pip install catboost imblearn joblib lightgbm matplotlib numpy optuna mlflow scikit-learn pandas seaborn tqdm ucimlrepo xgboost kaleido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-s_H70MgNNhA"
   },
   "outputs": [],
   "source": [
    "# Imports padrão do Python\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import warnings\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import combinations\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# Imports de bibliotecas de terceiros\n",
    "import catboost\n",
    "import joblib\n",
    "import lightgbm\n",
    "import matplotlib.gridspec as GridSpec\n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import scikit_posthocs as sp\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from lightgbm import LGBMClassifier\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "from pandas import DataFrame\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    StratifiedKFold,\n",
    "    cross_val_score,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from xgboost import XGBClassifier\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z5vMTMdThL5Z"
   },
   "outputs": [],
   "source": [
    "# Configurações\n",
    "np.random.seed(42)  # Para reprodutibilidade\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "# Parâmetros do algoritmo genético\n",
    "POPULATION_SIZE = 20\n",
    "MIN_FEATURES = 2\n",
    "MAX_FEATURES = 14  # Limitado pelo maior k testado\n",
    "MAX_GENERATIONS = 15\n",
    "ELITE_PERCENT = 0.2\n",
    "MUTATION_PROBABILITY = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nqXii3jw3zBD",
    "outputId": "ce69e10c-3053-4c4a-f6a2-618455b0017c"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hoSq3wgp2c_d",
    "outputId": "acdf10b9-fb73-4255-fc35-dc7dec0b0db0"
   },
   "outputs": [],
   "source": [
    "# %cd '/content/drive/MyDrive/TG - Data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CPEt6IaPNAhv"
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ujgL4khkNB__"
   },
   "outputs": [],
   "source": [
    "national_poll_on_healthy_agig_npha = fetch_ucirepo(id=936)\n",
    "X = national_poll_on_healthy_agig_npha.data.features\n",
    "y = national_poll_on_healthy_agig_npha.data.targets\n",
    "df = pd.merge(X, y, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbzCqOs9Mz5_"
   },
   "source": [
    "# 1. EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WUHv4kGorfPG"
   },
   "source": [
    "## Checagem básica\n",
    "Nessa etapa veremos a dimensão, se o dataset possui valores nulos e valores duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gt4d-qampp2k",
    "outputId": "b06d980e-3f48-48b9-9e13-a03c946f529a"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PklB-W4irpub",
    "outputId": "ff669fc1-7c3c-4089-9ac5-d8f5e4bb5a42"
   },
   "outputs": [],
   "source": [
    "print(f\"Qtde Valores Nulos: {df.isnull().sum()}\")\n",
    "\n",
    "print(f\"Qtde Valores Duplicados: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4R11hMrkmlV1"
   },
   "source": [
    "**Mapeamento dos Dados**: Irei alterar a distribuição de alguns dos valores para fazer mais sentido para minha ordenação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZDgqvoXlmwL8",
    "outputId": "b9ce9104-2279-4b08-c7a0-d3a2fac88853"
   },
   "outputs": [],
   "source": [
    "# Mapeamento dos valores das features conforme solicitado\n",
    "print(\"Aplicando mapeamento de valores às features...\")\n",
    "\n",
    "# Physical_Health e Mental_Health\n",
    "health_mapping = {-1: 0, 5: 1, 4: 2, 3: 3, 2: 4, 1: 5}\n",
    "df[\"Physical_Health\"] = (\n",
    "    df[\"Physical_Health\"].map(health_mapping).fillna(df[\"Physical_Health\"])\n",
    ")\n",
    "df[\"Mental_Health\"] = (\n",
    "    df[\"Mental_Health\"].map(health_mapping).fillna(df[\"Mental_Health\"])\n",
    ")\n",
    "\n",
    "# Dental_Health\n",
    "dental_mapping = {\n",
    "    -1: 0,\n",
    "    5: 1,\n",
    "    4: 2,\n",
    "    3: 3,\n",
    "    2: 4,\n",
    "    1: 5,\n",
    "}  # Usando 5 como substituição para 6\n",
    "# Verificar se algum valor 6 existe e substituir pela mediana se necessário\n",
    "if 6 in df[\"Dental_Health\"].values:\n",
    "    median_value = df[df[\"Dental_Health\"].between(1, 5)][\"Dental_Health\"].median()\n",
    "    dental_mapping[6] = median_value\n",
    "df[\"Dental_Health\"] = (\n",
    "    df[\"Dental_Health\"].map(dental_mapping).fillna(df[\"Dental_Health\"])\n",
    ")\n",
    "\n",
    "# Employment\n",
    "employment_mapping = {\n",
    "    1: 3,\n",
    "    2: 2,\n",
    "    3: 1,\n",
    "    4: 0,\n",
    "    -1: 0,\n",
    "}  # Adicionei -1: 0 para tratar recusas\n",
    "df[\"Employment\"] = df[\"Employment\"].map(employment_mapping).fillna(df[\"Employment\"])\n",
    "\n",
    "# Prescription_Sleep_Medication\n",
    "medication_mapping = {-1: 0, 1: 3, 2: 2, 3: 1}\n",
    "df[\"Prescription_Sleep_Medication\"] = (\n",
    "    df[\"Prescription_Sleep_Medication\"]\n",
    "    .map(medication_mapping)\n",
    "    .fillna(df[\"Prescription_Sleep_Medication\"])\n",
    ")\n",
    "\n",
    "# Mapeamento da target (Number_of_Doctors_Visited)\n",
    "target_mapping = {1: 0, 2: 1, 3: 2}\n",
    "print(\"Aplicando mapeamento de valores à target (Number_of_Doctors_Visited)...\")\n",
    "print(\n",
    "    f\"Distribuição original da target: {df['Number_of_Doctors_Visited'].value_counts()}\"\n",
    ")\n",
    "df[\"Number_of_Doctors_Visited\"] = (\n",
    "    df[\"Number_of_Doctors_Visited\"]\n",
    "    .map(target_mapping)\n",
    "    .fillna(df[\"Number_of_Doctors_Visited\"])\n",
    ")\n",
    "print(f\"Distribuição após mapeamento: {df['Number_of_Doctors_Visited'].value_counts()}\")\n",
    "\n",
    "# Converter todas as colunas para inteiros\n",
    "df = df.astype(int)\n",
    "\n",
    "print(\"Mapeamento concluído.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6YMa5d5-m0Vj"
   },
   "outputs": [],
   "source": [
    "feature_mappings = {\n",
    "    \"Number of Doctors Visited\": {1: \"0-1 doctors\", 2: \"2-3 doctors\", 3: \"4+ doctors\"},\n",
    "    \"Age\": {1: \"50-64\", 2: \"65-80\"},\n",
    "    \"Physical Health\": {\n",
    "        0: \"Refused\",\n",
    "        1: \"Poor\",\n",
    "        2: \"Fair\",\n",
    "        3: \"Good\",\n",
    "        4: \"Very Good\",\n",
    "        5: \"Excellent\",\n",
    "    },\n",
    "    \"Mental Health\": {\n",
    "        0: \"Refused\",\n",
    "        1: \"Poor\",\n",
    "        2: \"Fair\",\n",
    "        3: \"Good\",\n",
    "        4: \"Very Good\",\n",
    "        5: \"Excellent\",\n",
    "    },\n",
    "    \"Dental Health\": {\n",
    "        0: \"Refused\",\n",
    "        1: \"Poor\",\n",
    "        2: \"Fair\",\n",
    "        3: \"Good\",\n",
    "        4: \"Very Good\",\n",
    "        5: \"Excellent\",\n",
    "    },\n",
    "    \"Employment\": {\n",
    "        0: \"Not working/Refused\",\n",
    "        1: \"Retired\",\n",
    "        2: \"Working part-time\",\n",
    "        3: \"Working full-time\",\n",
    "    },\n",
    "    \"Stress Keeps Patient from Sleeping\": {0: \"No\", 1: \"Yes\"},\n",
    "    \"Medication Keeps Patient from Sleeping\": {0: \"No\", 1: \"Yes\"},\n",
    "    \"Pain Keeps Patient from Sleeping\": {0: \"No\", 1: \"Yes\"},\n",
    "    \"Bathroom Needs Keeps Patient from Sleeping\": {0: \"No\", 1: \"Yes\"},\n",
    "    \"Uknown Keeps Patient from Sleeping\": {0: \"No\", 1: \"Yes\"},\n",
    "    \"Trouble Sleeping\": {0: \"No\", 1: \"Yes\", 2: \"Sometimes\", 3: \"Unknown\"},\n",
    "    \"Prescription Sleep Medication\": {\n",
    "        0: \"Refused\",\n",
    "        1: \"Do not use\",\n",
    "        2: \"Use occasionally\",\n",
    "        3: \"Use regularly\",\n",
    "    },\n",
    "    \"Race\": {\n",
    "        -2: \"Not asked\",\n",
    "        -1: \"Refused\",\n",
    "        1: \"White, Non-Hispanic\",\n",
    "        2: \"Black, Non-Hispanic\",\n",
    "        3: \"Other, Non-Hispanic\",\n",
    "        4: \"Hispanic\",\n",
    "        5: \"2+ Races, Non-Hispanic\",\n",
    "    },\n",
    "    \"Gender\": {-2: \"Not asked\", -1: \"Refused\", 1: \"Male\", 2: \"Female\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3LgZr1KsmKa"
   },
   "source": [
    "**Conclusão da Etapa**: Nessa etapa vimos que não temos nenhum dado nulo, mas vimos que temos linhas duplicadas no conjunto de dados. Iremos removê-las na etapa de tratamento dos dados pois tratam-se de dados redundantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lguxmcr826mb"
   },
   "source": [
    "## Visualização dos Dados\n",
    "Nessa etapa iremos utilizar as visualizações de Barplots, Boxplots, Violin Plots e Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gdNEWCYE4or0"
   },
   "outputs": [],
   "source": [
    "# Função para criar um mosaico de barplots\n",
    "def create_barplot_mosaic(save_image=False, save_path=\".\"):\n",
    "    # Definir o número de colunas e calcular o número de linhas necessárias\n",
    "    n_cols = 3\n",
    "    n_rows = int(np.ceil(len(df.columns) / n_cols))\n",
    "\n",
    "    # Criar a figura\n",
    "    plt.figure(figsize=(20, 5 * n_rows))\n",
    "\n",
    "    # Plotar barplots para cada feature\n",
    "    for i, col in enumerate(df.columns):\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "\n",
    "        # Contar os valores para cada categoria\n",
    "        value_counts = df[col].value_counts().sort_index()\n",
    "\n",
    "        # Criar barplot\n",
    "        ax = sns.barplot(x=value_counts.index, y=value_counts.values)\n",
    "\n",
    "        # Ajustar os ticks do eixo x\n",
    "        plt.xticks(\n",
    "            range(len(value_counts)),\n",
    "            [str(val) for val in value_counts.index],\n",
    "            rotation=45,\n",
    "            ha=\"right\",\n",
    "        )\n",
    "\n",
    "        plt.title(f\"Distribuição de {col}\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "    plt.suptitle(\"Mosaico de Barplots para todas as Features\", fontsize=20, y=1.02)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_image:\n",
    "        plt.savefig(f\"{save_path}/barplot_mosaic.png\", dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Função para criar um mosaico de boxplots\n",
    "def create_boxplot_mosaic(save_image=False, save_path=\".\"):\n",
    "    # Definir o número de colunas e calcular o número de linhas necessárias\n",
    "    n_cols = 3\n",
    "    n_rows = int(np.ceil(len(df.columns) / n_cols))\n",
    "\n",
    "    # Criar a figura\n",
    "    plt.figure(figsize=(20, 5 * n_rows))\n",
    "\n",
    "    # Plotar boxplots para cada feature\n",
    "    for i, col in enumerate(df.columns):\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "\n",
    "        # Criar boxplot\n",
    "        sns.boxplot(x=df[col])\n",
    "\n",
    "        plt.title(f\"Boxplot de {col}\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "    plt.suptitle(\"Mosaico de Boxplots para todas as Features\", fontsize=20, y=1.02)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_image:\n",
    "        plt.savefig(f\"{save_path}/boxplot_mosaic.png\", dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Função para criar um mosaico de violin plots\n",
    "def create_violinplot_mosaic(save_image=False, save_path=\".\"):\n",
    "    # Definir o número de colunas e calcular o número de linhas necessárias\n",
    "    n_cols = 3\n",
    "    n_rows = int(np.ceil(len(df.columns) / n_cols))\n",
    "\n",
    "    # Criar a figura\n",
    "    plt.figure(figsize=(20, 5 * n_rows))\n",
    "\n",
    "    # Plotar violin plots para cada feature\n",
    "    for i, col in enumerate(df.columns):\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "\n",
    "        # Criar violin plot\n",
    "        sns.violinplot(x=df[col])\n",
    "\n",
    "        plt.title(f\"Violin Plot de {col}\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "    plt.suptitle(\"Mosaico de Violin Plots para todas as Features\", fontsize=20, y=1.02)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_image:\n",
    "        plt.savefig(f\"{save_path}/violinplot_mosaic.png\", dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Função para criar um mapa de calor de correlação\n",
    "def create_correlation_heatmap(save_image=False, save_path=\".\", linear_corr=True):\n",
    "    # Criar a figura\n",
    "    plt.figure(figsize=(16, 14))\n",
    "\n",
    "    # Calcular a matriz de correlação\n",
    "    if linear_corr:\n",
    "        corr_matrix = df.corr(method=\"pearson\")\n",
    "    else:\n",
    "        corr_matrix = df.corr(method=\"spearman\")\n",
    "\n",
    "    # Criar o mapa de calor\n",
    "    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "    sns.heatmap(\n",
    "        corr_matrix,\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        cmap=\"coolwarm\",\n",
    "        mask=mask,\n",
    "        square=True,\n",
    "        linewidths=0.5,\n",
    "    )\n",
    "\n",
    "    plt.title(\"Mapa de Calor de Correlação\", fontsize=20)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_image:\n",
    "        plt.savefig(\n",
    "            f\"{save_path}/correlation_heatmap.png\", dpi=300, bbox_inches=\"tight\"\n",
    "        )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Função para criar um mosaico de scatter plots entre o target e as features\n",
    "def create_scatter_mosaic(save_image=False, save_path=\".\"):\n",
    "    target = \"Number_of_Doctors_Visited\"\n",
    "    features = [col for col in df.columns if col != target]\n",
    "\n",
    "    # Definir o número de colunas e calcular o número de linhas necessárias\n",
    "    n_cols = 3\n",
    "    n_rows = int(np.ceil(len(features) / n_cols))\n",
    "\n",
    "    # Criar a figura\n",
    "    plt.figure(figsize=(20, 5 * n_rows))\n",
    "\n",
    "    # Mapear as cores para os valores do target\n",
    "    colors = {1: \"blue\", 2: \"green\", 3: \"red\"}\n",
    "\n",
    "    # Plotar a relação de cada feature com o target usando scatter plot\n",
    "    for i, feature in enumerate(features):\n",
    "        plt.subplot(n_rows, n_cols, i + 1)\n",
    "\n",
    "        # Adicionar jitter para melhor visualização (dados discretos podem se sobrepor)\n",
    "        x = df[feature] + np.random.normal(0, 0.1, size=len(df))\n",
    "        y = df[target] + np.random.normal(0, 0.1, size=len(df))\n",
    "\n",
    "        # Criar scatter plot com cores baseadas no target\n",
    "        for target_val in sorted(df[target].unique()):\n",
    "            mask = df[target] == target_val\n",
    "            plt.scatter(\n",
    "                x[mask],\n",
    "                y[mask],\n",
    "                alpha=0.5,\n",
    "                label=f\"Classe {target_val}\",\n",
    "                color=colors.get(target_val, f\"C{target_val}\"),\n",
    "            )\n",
    "\n",
    "        # Ajustar limites para melhor visualização\n",
    "        plt.xlim(df[feature].min() - 0.5, df[feature].max() + 0.5)\n",
    "        plt.ylim(df[target].min() - 0.5, df[target].max() + 0.5)\n",
    "\n",
    "        # Ajustar ticks para mostrar apenas os valores originais\n",
    "        plt.xticks(sorted(df[feature].unique()))\n",
    "        plt.yticks(sorted(df[target].unique()))\n",
    "\n",
    "        # Adicionar linhas de grade para facilitar a visualização\n",
    "        plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "        plt.xlabel(feature)\n",
    "        plt.ylabel(target)\n",
    "        plt.title(f\"Relação entre {feature} e {target}\")\n",
    "\n",
    "        # Adicionar legenda apenas no primeiro gráfico\n",
    "        if i == 0:\n",
    "            plt.legend()\n",
    "\n",
    "    plt.suptitle(\n",
    "        f\"Scatter Plots: Relações entre Features e {target}\", fontsize=20, y=1.02\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_image:\n",
    "        plt.savefig(f\"{save_path}/scatter_mosaic.png\", dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Bbgw1teE5nnN",
    "outputId": "407ec76f-237d-4aa1-c50c-defc11f9fcbc"
   },
   "outputs": [],
   "source": [
    "create_barplot_mosaic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "grj4_zmUnOwi",
    "outputId": "fd4aef58-2828-4ccd-d4f1-ff8007db2b37"
   },
   "outputs": [],
   "source": [
    "create_boxplot_mosaic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "BMxFQQxYnQCe",
    "outputId": "e4b37545-516c-473b-9916-951852fcce15"
   },
   "outputs": [],
   "source": [
    "create_violinplot_mosaic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "v9sg43qOnFzE",
    "outputId": "932df2d6-e90f-429e-e14e-11cc04c0adb0"
   },
   "outputs": [],
   "source": [
    "create_scatter_mosaic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9JJc0v8MnmKX",
    "outputId": "803af820-a2aa-40fd-e3b7-967c0b481f9d"
   },
   "outputs": [],
   "source": [
    "create_correlation_heatmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iGcxSr9nniMc"
   },
   "source": [
    "**Conclusão**: Ao analisar as features, tivemos as seguintes conclusões\n",
    "1. No geral, muitas features do dataset apresentam pouca variabilidade\n",
    "2. A target não tem uma correlaÇão linear muito forte com nenhuma feature\n",
    "3. O número de visitas aos médicos não tem correlação com o estado mental dos indivíduos. Isso é inesperado.\n",
    "4. A coluna de idade e gênero não tem correlação nenhuma com a target e podem ser dropada.\n",
    "5. Por termos apenas variáveis categóricas e binárias, não teremos necessidade\n",
    "de normalizar as features\n",
    "6. O ideal é que usemos o SMOTE na etapa de treinamento devido ao desbalancemanto das features\n",
    "7. Não temos colunas duplas, então não precisaremos fazer imputação das features, mas precisaremos remover as features duplicadas.\n",
    "8. Um repameanto dos valores das features foi feito para fazer mais sentido e\n",
    "precisamos mudar o valor '6' de Dental_Health para o valor da mediana, já que ele não estava presente\n",
    "na descrição do dataset, indicando um ruído.\n",
    "9. Trouble sleeping terá que ser dropada pois ela deveria ser binária e apresenta 3 valores (1, 2 e 3). Isso indica forte ruído e não tenho ideias\n",
    "de como corrigir isso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iDy8VmVbtwiC"
   },
   "source": [
    "# 2. Data Cleaning\n",
    "Visando a Preparar o Conjunto de Dados para a modelagem, nessa etapa:\n",
    "1. Iremos remover as linhas duplicadas\n",
    "2. Iremos dividir os dados em 10 conjuntos menores utilizando o StratifiedKfold, além de enriquecermos os dados de treino utilizando SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3LfAShwNWbWR"
   },
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q6RuX3Ez8xKr",
    "outputId": "10fb3428-de7e-4f17-8f32-a527414bf6d0"
   },
   "outputs": [],
   "source": [
    "# Preparar X e y\n",
    "X = df.drop(\"Number_of_Doctors_Visited\", axis=1)\n",
    "y = df[\"Number_of_Doctors_Visited\"]\n",
    "\n",
    "# Inicializar StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "\n",
    "# Inicializar SMOTE\n",
    "smote = SMOTE()\n",
    "\n",
    "# Lista para armazenar os folds\n",
    "smote_folds_data = []\n",
    "original_folds_data = []\n",
    "\n",
    "# Para cada fold\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    # Obter os subconjuntos originais\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # Aplicar SMOTE no conjunto de treino\n",
    "    X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Converter para DataFrame se X_train_smote retornar um array\n",
    "    if not isinstance(X_train_smote, pd.DataFrame):\n",
    "        X_train_smote = pd.DataFrame(X_train_smote, columns=X.columns)\n",
    "\n",
    "    # Mostrar distribuição das classes antes e depois do SMOTE\n",
    "    print(f\"Fold - Distribuição original: {Counter(y_train)}\")\n",
    "    print(f\"Fold - Distribuição após SMOTE: {Counter(y_train_smote)}\")\n",
    "\n",
    "    # Adicionar o fold à lista\n",
    "    smote_folds_data.append((X_train_smote, X_test, y_train_smote, y_test))\n",
    "    original_folds_data.append((X_train, X_test, y_train, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s8oqVG-ZcwDu"
   },
   "source": [
    "# 3. Feature Engineering\n",
    "Nesta etapa iremos escolher as melhores features do dataset com a seguinte metodologia:\n",
    "1. Utilizaremos LR, RF, KNN, NB e Catboost para avaliar os datasets.\n",
    "2. Separaremos uma cópia do dataset original\n",
    "3. Utilizaremos o método anova e selecionaremos *k* features, com o valor de *k* variando entre 7 e 11 features, em que tiraremos a media do AUC_SCORE para o grupo de classificadores avaliadores. O *k* com melhor média será escolhido para a avalição final.\n",
    "4. Utilizaremos algoritmo genético junto com random forests para selecionar o melhor subconjunto de features utilizando uma abordagem do tipo *wrapper*\n",
    "5. Selecionaremos as features com melhor média de auc_score para o conjunto de classificadores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mES5abXnfK1e"
   },
   "source": [
    "## Funções MlFlow Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tICuIaYHfK1f"
   },
   "outputs": [],
   "source": [
    "def setup_mlflow(experiment_name=\"Busca das Features\", sqlite_path=\"mlruns.db\"):\n",
    "    \"\"\"\n",
    "    Configura o MLflow para registrar experimentos em um banco de dados SQLite\n",
    "\n",
    "    Args:\n",
    "        experiment_name: Nome do experimento\n",
    "        sqlite_path: Caminho para o arquivo SQLite\n",
    "\n",
    "    Returns:\n",
    "        experiment_id: ID do experimento criado ou recuperado\n",
    "    \"\"\"\n",
    "    # Configurar o tracking URI para o SQLite\n",
    "    mlflow_tracking_uri = f\"sqlite:///{sqlite_path}\"\n",
    "    mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "\n",
    "    # Criar ou obter o experimento\n",
    "    try:\n",
    "        experiment_id = mlflow.create_experiment(\n",
    "            experiment_name, artifact_location=os.path.join(os.getcwd(), \"mlruns\")\n",
    "        )\n",
    "        print(f\"Experimento '{experiment_name}' criado com ID: {experiment_id}\")\n",
    "    except mlflow.exceptions.MlflowException:\n",
    "        # Experimento já existe, recuperar ID\n",
    "        experiment_id = mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "        print(f\"Experimento '{experiment_name}' já existe com ID: {experiment_id}\")\n",
    "\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    return experiment_id\n",
    "\n",
    "\n",
    "def log_feature_selection_results(\n",
    "    model_name, model, method, features, mean_auc, std_auc, fold_aucs, k=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Registra os resultados de um método de seleção de features no MLflow\n",
    "\n",
    "    Args:\n",
    "        model_name: Nome do modelo\n",
    "        model: Objeto do modelo scikit-learn\n",
    "        method: Nome do método de seleção de features ('all', 'anova', 'ga')\n",
    "        features: Lista de features selecionadas\n",
    "        mean_auc: AUC-ROC médio\n",
    "        std_auc: Desvio padrão do AUC-ROC\n",
    "        fold_aucs: Lista de AUC-ROC para cada fold\n",
    "        k: Valor de k para o método ANOVA (opcional)\n",
    "    \"\"\"\n",
    "    # Mapear o nome do método para um nome mais descritivo\n",
    "    method_names = {\n",
    "        \"all\": \"Todas as Features\",\n",
    "        \"anova\": f\"ANOVA (k={k})\" if k else \"ANOVA\",\n",
    "        \"ga\": \"Algoritmo Genético\",\n",
    "    }\n",
    "\n",
    "    # Iniciar o run com o nome do modelo e método\n",
    "    run_name = f\"{model_name} - {method_names[method]}\"\n",
    "\n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        # Registrar os parâmetros\n",
    "        params = {\n",
    "            \"model_name\": model_name,\n",
    "            \"feature_selection_method\": method_names[method],\n",
    "            \"num_features\": len(features),\n",
    "        }\n",
    "\n",
    "        # Adicionar k se o método for ANOVA\n",
    "        if method == \"anova\" and k is not None:\n",
    "            params[\"anova_k\"] = k\n",
    "\n",
    "        # Registrar os parâmetros do modelo se disponíveis\n",
    "        if hasattr(model, \"get_params\"):\n",
    "            model_params = model.get_params()\n",
    "            for param_name, param_value in model_params.items():\n",
    "                # Converter qualquer valor não serializado para string\n",
    "                if not isinstance(param_value, (int, float, str, bool, type(None))):\n",
    "                    param_value = str(param_value)\n",
    "                params[f\"model_{param_name}\"] = param_value\n",
    "\n",
    "        # Registrar todos os parâmetros\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # Registrar as métricas\n",
    "        metrics = {\n",
    "            \"mean_auc\": mean_auc,\n",
    "            \"std_auc\": std_auc,\n",
    "            \"min_auc\": np.min(fold_aucs),\n",
    "            \"max_auc\": np.max(fold_aucs),\n",
    "            \"median_auc\": np.median(fold_aucs),\n",
    "        }\n",
    "\n",
    "        # Registrar cada fold individualmente\n",
    "        for i, fold_auc in enumerate(fold_aucs):\n",
    "            metrics[f\"fold_{i+1}_auc\"] = fold_auc\n",
    "\n",
    "        # Registrar todas as métricas\n",
    "        mlflow.log_metrics(metrics)\n",
    "\n",
    "        # Registrar as features como um artefato\n",
    "        pd.DataFrame({\"feature\": features}).to_csv(\"selected_features.csv\", index=False)\n",
    "        mlflow.log_artifact(\"selected_features.csv\")\n",
    "\n",
    "        # Registrar o modelo se aplicável\n",
    "        try:\n",
    "            mlflow.sklearn.log_model(model, \"model\")\n",
    "        except Exception as e:\n",
    "            print(f\"Aviso: Não foi possível registrar o modelo: {e}\")\n",
    "\n",
    "        # Registrar link para o tracking server\n",
    "        tracking_url = mlflow.get_tracking_uri()\n",
    "        print(f\"MLflow Tracking URL: {tracking_url}\")\n",
    "\n",
    "        # Capturar o ID do run para referência\n",
    "        run_id = mlflow.active_run().info.run_id\n",
    "        print(f\"Run ID: {run_id}\")\n",
    "\n",
    "        return run_id\n",
    "\n",
    "\n",
    "def log_all_results_to_mlflow(results):\n",
    "    \"\"\"\n",
    "    Registra todos os resultados de seleção de features no MLflow\n",
    "\n",
    "    Args:\n",
    "        results: Dicionário com resultados por modelo e método de seleção\n",
    "    \"\"\"\n",
    "    # Configurar MLflow\n",
    "    experiment_id = setup_mlflow()\n",
    "\n",
    "    # Obter dicionário de modelos\n",
    "\n",
    "    model_dict = get_model_dict()\n",
    "\n",
    "    # Para cada modelo\n",
    "    for model_name, model_results in results.items():\n",
    "        print(f\"\\nRegistrando resultados para {model_name}...\")\n",
    "\n",
    "        # Obter o objeto do modelo\n",
    "        model = model_dict.get(model_name)\n",
    "\n",
    "        # Registrar resultados para todas as features\n",
    "        all_features_results = model_results[\"all_features\"]\n",
    "        log_feature_selection_results(\n",
    "            model_name=model_name,\n",
    "            model=model,\n",
    "            method=\"all\",\n",
    "            features=all_features_results[\"features\"],\n",
    "            mean_auc=all_features_results[\"mean_auc\"],\n",
    "            std_auc=all_features_results[\"std_auc\"],\n",
    "            fold_aucs=all_features_results[\"fold_aucs\"],\n",
    "        )\n",
    "\n",
    "        # Registrar resultados para ANOVA\n",
    "        best_k = model_results[\"anova\"][\"best_k\"]\n",
    "        anova_results = model_results[\"anova\"][\"best_results\"]\n",
    "        log_feature_selection_results(\n",
    "            model_name=model_name,\n",
    "            model=model,\n",
    "            method=\"anova\",\n",
    "            features=anova_results[\"features\"],\n",
    "            mean_auc=anova_results[\"mean_auc\"],\n",
    "            std_auc=anova_results[\"std_auc\"],\n",
    "            fold_aucs=anova_results[\"fold_aucs\"],\n",
    "            k=best_k,\n",
    "        )\n",
    "\n",
    "        # Registrar resultados para Algoritmo Genético\n",
    "        ga_results = model_results[\"ga\"]\n",
    "        fold_aucs = [result[\"auc\"] for result in ga_results[\"fold_results\"]]\n",
    "        log_feature_selection_results(\n",
    "            model_name=model_name,\n",
    "            model=model,\n",
    "            method=\"ga\",\n",
    "            features=ga_results[\"common_features\"],\n",
    "            mean_auc=ga_results[\"mean_auc\"],\n",
    "            std_auc=ga_results[\"std_auc\"],\n",
    "            fold_aucs=fold_aucs,\n",
    "        )\n",
    "\n",
    "    print(\n",
    "        f\"\\nTodos os resultados foram registrados no experimento MLflow (ID: {experiment_id})\"\n",
    "    )\n",
    "    print(f\"MLflow Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "\n",
    "    # Instruções para visualizar os resultados\n",
    "    print(\n",
    "        \"\\nPara visualizar os resultados no UI do MLflow, execute o seguinte comando no terminal:\"\n",
    "    )\n",
    "    print(f\"mlflow ui --backend-store-uri {mlflow.get_tracking_uri()}\")\n",
    "\n",
    "\n",
    "def log_best_models_to_mlflow(results):\n",
    "    \"\"\"\n",
    "    Registra apenas os melhores modelos/métodos no MLflow\n",
    "\n",
    "    Args:\n",
    "        results: Dicionário com resultados por modelo e método de seleção\n",
    "    \"\"\"\n",
    "    # Configurar MLflow\n",
    "    experiment_name = \"Melhores Modelos de Seleção de Features\"\n",
    "    experiment_id = setup_mlflow(experiment_name)\n",
    "\n",
    "    model_dict = get_model_dict()\n",
    "\n",
    "    best_models = []\n",
    "\n",
    "    # Para cada modelo\n",
    "    for model_name, model_results in results.items():\n",
    "        # Obter o objeto do modelo\n",
    "        model = model_dict.get(model_name)\n",
    "\n",
    "        # Obter AUC para cada método\n",
    "        all_features_auc = model_results[\"all_features\"][\"mean_auc\"]\n",
    "        anova_auc = model_results[\"anova\"][\"best_results\"][\"mean_auc\"]\n",
    "        ga_auc = model_results[\"ga\"][\"mean_auc\"]\n",
    "\n",
    "        # Determinar o melhor método\n",
    "        methods = [\"all\", \"anova\", \"ga\"]\n",
    "        method_names = [\"Todas as Features\", \"ANOVA\", \"Algoritmo Genético\"]\n",
    "        aucs = [all_features_auc, anova_auc, ga_auc]\n",
    "        best_idx = np.argmax(aucs)\n",
    "        best_method = methods[best_idx]\n",
    "        best_method_name = method_names[best_idx]\n",
    "\n",
    "        # Obter dados do melhor método\n",
    "        if best_method == \"all\":\n",
    "            best_results = model_results[\"all_features\"]\n",
    "            features = best_results[\"features\"]\n",
    "            fold_aucs = best_results[\"fold_aucs\"]\n",
    "            k = None\n",
    "        elif best_method == \"anova\":\n",
    "            best_k = model_results[\"anova\"][\"best_k\"]\n",
    "            best_results = model_results[\"anova\"][\"best_results\"]\n",
    "            features = best_results[\"features\"]\n",
    "            fold_aucs = best_results[\"fold_aucs\"]\n",
    "            k = best_k\n",
    "        else:  # ga\n",
    "            best_results = model_results[\"ga\"]\n",
    "            features = best_results[\"common_features\"]\n",
    "            fold_aucs = [result[\"auc\"] for result in best_results[\"fold_results\"]]\n",
    "            k = None\n",
    "\n",
    "        # Registrar o melhor método\n",
    "        run_id = log_feature_selection_results(\n",
    "            model_name=model_name,\n",
    "            model=model,\n",
    "            method=best_method,\n",
    "            features=features,\n",
    "            mean_auc=best_results[\"mean_auc\"],\n",
    "            std_auc=best_results[\"std_auc\"],\n",
    "            fold_aucs=fold_aucs,\n",
    "            k=k,\n",
    "        )\n",
    "\n",
    "        # Adicionar à lista de melhores modelos\n",
    "        best_models.append(\n",
    "            {\n",
    "                \"model_name\": model_name,\n",
    "                \"best_method\": best_method_name,\n",
    "                \"auc\": best_results[\"mean_auc\"],\n",
    "                \"num_features\": len(features),\n",
    "                \"run_id\": run_id,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Criar DataFrame para resumo dos melhores modelos\n",
    "    best_df = pd.DataFrame(best_models)\n",
    "    best_df = best_df.sort_values(\"auc\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Salvar e registrar como artefato\n",
    "    with mlflow.start_run(run_name=\"Resumo dos Melhores Modelos\"):\n",
    "        best_df.to_csv(\"best_models_summary.csv\", index=False)\n",
    "        mlflow.log_artifact(\"best_models_summary.csv\")\n",
    "\n",
    "        # Registrar métricas gerais\n",
    "        mlflow.log_metric(\"num_models\", len(best_df))\n",
    "        mlflow.log_metric(\"max_auc\", best_df[\"auc\"].max())\n",
    "        mlflow.log_metric(\"mean_auc\", best_df[\"auc\"].mean())\n",
    "\n",
    "        # Contar quantas vezes cada método foi o melhor\n",
    "        method_counts = best_df[\"best_method\"].value_counts()\n",
    "        for method, count in method_counts.items():\n",
    "            mlflow.log_metric(f\"{method.replace(' ', '_')}_count\", count)\n",
    "\n",
    "    print(\n",
    "        f\"\\nResumo dos melhores modelos registrado no experimento MLflow (ID: {experiment_id})\"\n",
    "    )\n",
    "    print(f\"MLflow Tracking URI: {mlflow.get_tracking_uri()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cbc5gKvKgRZl"
   },
   "source": [
    "## Funções Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6QkTBPCAgO-f"
   },
   "outputs": [],
   "source": [
    "def get_model_dict():\n",
    "    return {\n",
    "        \"Decision Trees\": DecisionTreeClassifier(random_state=42),\n",
    "        \"Gradient Tree Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "        \"k-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "        \"LightGBM\": LGBMClassifier(random_state=42),\n",
    "        \"Multinomial Logistic Regression\": LogisticRegression(\n",
    "            multi_class=\"multinomial\", solver=\"lbfgs\", max_iter=1000, random_state=42\n",
    "        ),\n",
    "        \"Naive Bayes\": GaussianNB(),\n",
    "        \"Random Forests\": RandomForestClassifier(random_state=42),\n",
    "        \"Support Vector Machines\": SVC(probability=True, random_state=42),\n",
    "        \"XGBoost\": XGBClassifier(random_state=42),\n",
    "        \"CatBoost\": CatBoostClassifier(verbose=False, random_state=42),\n",
    "    }\n",
    "\n",
    "\n",
    "# 1. Seleção de features por ANOVA para cada modelo\n",
    "def select_features_anova(X_train, y_train, k):\n",
    "    \"\"\"Seleciona k features usando o método ANOVA\"\"\"\n",
    "    selector = SelectKBest(f_classif, k=k)\n",
    "    selector.fit(X_train, y_train)\n",
    "\n",
    "    # Obter os índices das features selecionadas\n",
    "    selected_indices = selector.get_support(indices=True)\n",
    "\n",
    "    # Obter os nomes das features selecionadas\n",
    "    selected_features = X_train.columns[selected_indices]\n",
    "\n",
    "    return selected_features\n",
    "\n",
    "\n",
    "# 2. Avaliar conjunto de features com um classificador específico\n",
    "def evaluate_features_with_model(model, X_train, X_test, y_train, y_test, features):\n",
    "    \"\"\"Avalia um conjunto de features usando um classificador específico\"\"\"\n",
    "    # Selecionar apenas as features escolhidas\n",
    "    X_train_selected = X_train[features]\n",
    "    X_test_selected = X_test[features]\n",
    "\n",
    "    # Clonar o modelo para evitar contaminação\n",
    "    model_clone = clone_model(model)\n",
    "\n",
    "    # Verificar se as classes já começam em 0 (apenas para logging)\n",
    "    min_class = min(np.unique(y_train))\n",
    "    if min_class == 0:\n",
    "        print(f\"Classes já começam em 0: {sorted(np.unique(y_train))}\")\n",
    "\n",
    "    # Treinar o modelo diretamente (sem mapeamento de classes)\n",
    "    try:\n",
    "        # Treinar o modelo\n",
    "        model_clone.fit(X_train_selected, y_train)\n",
    "\n",
    "        # Calcular AUC score\n",
    "        if hasattr(model_clone, \"predict_proba\"):\n",
    "            y_prob = model_clone.predict_proba(X_test_selected)\n",
    "            auc = roc_auc_score(y_test, y_prob, multi_class=\"ovr\", average=\"macro\")\n",
    "        else:\n",
    "            # Para classificadores que não têm predict_proba\n",
    "            auc = 0.5  # Valor padrão, pior cenário\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao treinar/avaliar modelo {type(model_clone).__name__}: {e}\")\n",
    "        auc = 0.5  # Valor padrão em caso de erro\n",
    "\n",
    "    return auc\n",
    "\n",
    "\n",
    "# Função auxiliar para clonar um modelo\n",
    "def clone_model(model):\n",
    "    \"\"\"Cria uma cópia nova do modelo com os mesmos parâmetros\"\"\"\n",
    "    from sklearn.base import clone\n",
    "\n",
    "    return clone(model)\n",
    "\n",
    "\n",
    "# 3. Testar diferentes valores de k com ANOVA para um modelo específico\n",
    "def evaluate_anova_for_model(model, folds_data, k_values=range(7, 15)):\n",
    "    \"\"\"Testa ANOVA com diferentes valores de k para um modelo específico em todos os folds\"\"\"\n",
    "    k_results = {}\n",
    "    best_k = None\n",
    "    best_mean_auc = 0\n",
    "\n",
    "    for k in k_values:\n",
    "        fold_aucs = []\n",
    "\n",
    "        for fold_idx, (X_train, X_test, y_train, y_test) in enumerate(folds_data):\n",
    "            # Selecionar features usando ANOVA\n",
    "            selected_features = select_features_anova(X_train, y_train, k)\n",
    "\n",
    "            # Avaliar com o modelo específico\n",
    "            auc = evaluate_features_with_model(\n",
    "                model, X_train, X_test, y_train, y_test, selected_features\n",
    "            )\n",
    "            fold_aucs.append(auc)\n",
    "\n",
    "        # Calcular média e desvio padrão dos AUCs nos folds\n",
    "        mean_auc = np.mean(fold_aucs)\n",
    "        std_auc = np.std(fold_aucs)\n",
    "\n",
    "        # Armazenar resultados\n",
    "        k_results[k] = {\n",
    "            \"fold_aucs\": fold_aucs,\n",
    "            \"mean_auc\": mean_auc,\n",
    "            \"std_auc\": std_auc,\n",
    "            \"features\": selected_features,  # Usa o último fold como referência para features\n",
    "        }\n",
    "\n",
    "        # Verificar se este é o melhor k\n",
    "        if mean_auc > best_mean_auc:\n",
    "            best_mean_auc = mean_auc\n",
    "            best_k = k\n",
    "\n",
    "    return k_results, best_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMByilmhkFV_"
   },
   "source": [
    "## Funções do Algoritmo Genético\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V4rqeC4AkXI2"
   },
   "outputs": [],
   "source": [
    "# 4. Funções para o algoritmo genético\n",
    "def generate_initial_population(n_features):\n",
    "    \"\"\"Gera a população inicial de cromossomos\"\"\"\n",
    "    population = np.zeros((POPULATION_SIZE, n_features))\n",
    "\n",
    "    for i in range(POPULATION_SIZE):\n",
    "        # Determinar quantas features selecionar (entre MIN_FEATURES e MAX_FEATURES)\n",
    "        n_selected = np.random.randint(MIN_FEATURES, min(MAX_FEATURES + 1, n_features))\n",
    "\n",
    "        # Escolher aleatoriamente quais features selecionar\n",
    "        selected_indices = np.random.choice(n_features, n_selected, replace=False)\n",
    "        population[i, selected_indices] = 1\n",
    "\n",
    "    return population\n",
    "\n",
    "\n",
    "def evaluate_chromosome(\n",
    "    model, X_train, X_test, y_train, y_test, chromosome, feature_names\n",
    "):\n",
    "    \"\"\"Avalia um cromossomo usando o modelo especificado\"\"\"\n",
    "    # Selecionar as features de acordo com o cromossomo\n",
    "    selected_features = feature_names[chromosome == 1]\n",
    "\n",
    "    if len(selected_features) == 0:\n",
    "        # Se nenhuma feature for selecionada, atribuir AUC zero\n",
    "        return 0\n",
    "\n",
    "    # Avaliar usando o modelo\n",
    "    auc = evaluate_features_with_model(\n",
    "        model, X_train, X_test, y_train, y_test, selected_features\n",
    "    )\n",
    "\n",
    "    return auc\n",
    "\n",
    "\n",
    "def evaluate_population(\n",
    "    model, population, X_train, X_test, y_train, y_test, feature_names\n",
    "):\n",
    "    \"\"\"Avalia toda a população de cromossomos\"\"\"\n",
    "    fitness_scores = np.zeros(POPULATION_SIZE)\n",
    "\n",
    "    for i in range(POPULATION_SIZE):\n",
    "        fitness_scores[i] = evaluate_chromosome(\n",
    "            model, X_train, X_test, y_train, y_test, population[i], feature_names\n",
    "        )\n",
    "\n",
    "    return fitness_scores\n",
    "\n",
    "\n",
    "def select_parents(population, fitness_scores):\n",
    "    \"\"\"Seleciona pais usando Roulette Wheel Selection\"\"\"\n",
    "    # Número de elite (melhores indivíduos que serão mantidos para a próxima geração)\n",
    "    elite_count = int(POPULATION_SIZE * ELITE_PERCENT)\n",
    "\n",
    "    # Índices dos elite_count melhores indivíduos\n",
    "    elite_indices = np.argsort(fitness_scores)[-elite_count:]\n",
    "\n",
    "    # Seleção dos pais para o restante da população usando roleta\n",
    "    weights = fitness_scores / (\n",
    "        np.sum(fitness_scores) + 1e-10\n",
    "    )  # Normalizar para soma = 1\n",
    "    cumulative_weights = np.cumsum(weights)\n",
    "\n",
    "    parents = np.zeros_like(population)\n",
    "\n",
    "    # Primeiro adicionar a elite\n",
    "    parents[:elite_count] = population[elite_indices]\n",
    "\n",
    "    # Depois selecionar o restante usando a roleta\n",
    "    for i in range(elite_count, POPULATION_SIZE):\n",
    "        r = np.random.random()\n",
    "        idx = np.searchsorted(cumulative_weights, r)\n",
    "        if idx >= len(population):\n",
    "            idx = len(population) - 1\n",
    "        parents[i] = population[idx]\n",
    "\n",
    "    return parents\n",
    "\n",
    "\n",
    "def crossover_and_mutate(parents, n_features):\n",
    "    \"\"\"Aplica crossover e mutação nos pais para gerar filhos\"\"\"\n",
    "    # Número de elite que será preservado\n",
    "    elite_count = int(POPULATION_SIZE * ELITE_PERCENT)\n",
    "\n",
    "    # Criar array para a nova população\n",
    "    children = np.zeros_like(parents)\n",
    "\n",
    "    # Manter a elite\n",
    "    children[:elite_count] = parents[:elite_count]\n",
    "\n",
    "    # Aplicar crossover no restante\n",
    "    for i in range(elite_count, POPULATION_SIZE, 2):\n",
    "        if i + 1 < POPULATION_SIZE:\n",
    "            # Selecionar dois pais aleatoriamente\n",
    "            parent_idx1 = np.random.randint(0, POPULATION_SIZE)\n",
    "            parent_idx2 = np.random.randint(0, POPULATION_SIZE)\n",
    "\n",
    "            # Escolher ponto de crossover\n",
    "            crossover_point = np.random.randint(1, n_features)\n",
    "\n",
    "            # Criar filhos com o crossover\n",
    "            children[i, :crossover_point] = parents[parent_idx1, :crossover_point]\n",
    "            children[i, crossover_point:] = parents[parent_idx2, crossover_point:]\n",
    "\n",
    "            children[i + 1, :crossover_point] = parents[parent_idx2, :crossover_point]\n",
    "            children[i + 1, crossover_point:] = parents[parent_idx1, crossover_point:]\n",
    "\n",
    "    # Aplicar mutação em cada filho, exceto na elite\n",
    "    for i in range(elite_count, POPULATION_SIZE):\n",
    "        for j in range(n_features):\n",
    "            if np.random.random() < MUTATION_PROBABILITY:\n",
    "                # Inverter o bit (0->1 ou 1->0)\n",
    "                children[i, j] = 1 - children[i, j]\n",
    "\n",
    "        # Garantir que o número de features esteja dentro dos limites\n",
    "        selected_count = np.sum(children[i])\n",
    "\n",
    "        if selected_count < MIN_FEATURES:\n",
    "            # Adicionar features se abaixo do mínimo\n",
    "            zeros_indices = np.where(children[i] == 0)[0]\n",
    "            if len(zeros_indices) > 0:\n",
    "                add_count = min(MIN_FEATURES - selected_count, len(zeros_indices))\n",
    "                add_indices = np.random.choice(\n",
    "                    zeros_indices, int(add_count), replace=False\n",
    "                )\n",
    "                children[i, add_indices] = 1\n",
    "\n",
    "        elif selected_count > MAX_FEATURES:\n",
    "            # Remover features se acima do máximo\n",
    "            ones_indices = np.where(children[i] == 1)[0]\n",
    "            if len(ones_indices) > 0:\n",
    "                remove_count = min(selected_count - MAX_FEATURES, len(ones_indices))\n",
    "                remove_indices = np.random.choice(\n",
    "                    ones_indices, int(remove_count), replace=False\n",
    "                )\n",
    "                children[i, remove_indices] = 0\n",
    "\n",
    "    return children\n",
    "\n",
    "\n",
    "def run_genetic_algorithm_for_model(model, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Executa o algoritmo genético para um modelo específico em um fold específico\"\"\"\n",
    "    n_features = X_train.shape[1]\n",
    "    feature_names = X_train.columns\n",
    "\n",
    "    # Inicializar população\n",
    "    population = generate_initial_population(n_features)\n",
    "\n",
    "    # Armazenar o melhor fitness de cada geração\n",
    "    best_fitness_history = np.zeros(MAX_GENERATIONS)\n",
    "    best_chromosome = None\n",
    "    best_fitness = 0\n",
    "\n",
    "    # Executar por MAX_GENERATIONS gerações\n",
    "    for generation in range(MAX_GENERATIONS):\n",
    "        # Avaliar população atual\n",
    "        fitness_scores = evaluate_population(\n",
    "            model, population, X_train, X_test, y_train, y_test, feature_names\n",
    "        )\n",
    "\n",
    "        # Armazenar o melhor dessa geração\n",
    "        generation_best_idx = np.argmax(fitness_scores)\n",
    "        generation_best_fitness = fitness_scores[generation_best_idx]\n",
    "        best_fitness_history[generation] = generation_best_fitness\n",
    "\n",
    "        # Atualizar o melhor global\n",
    "        if generation_best_fitness > best_fitness:\n",
    "            best_fitness = generation_best_fitness\n",
    "            best_chromosome = population[generation_best_idx].copy()\n",
    "\n",
    "        # Selecionar pais\n",
    "        parents = select_parents(population, fitness_scores)\n",
    "\n",
    "        # Criar nova população com crossover e mutação\n",
    "        population = crossover_and_mutate(parents, n_features)\n",
    "\n",
    "    # Selecionar as features com base no melhor cromossomo\n",
    "    if best_chromosome is not None:\n",
    "        selected_features = feature_names[best_chromosome == 1]\n",
    "    else:\n",
    "        # Caso de falha, selecionar algumas features aleatórias\n",
    "        selected_count = min(MAX_FEATURES, len(feature_names))\n",
    "        selected_features = np.random.choice(\n",
    "            feature_names, selected_count, replace=False\n",
    "        )\n",
    "\n",
    "    return selected_features, best_fitness, best_fitness_history\n",
    "\n",
    "\n",
    "def evaluate_ga_for_model(model, folds_data):\n",
    "    \"\"\"Avalia o algoritmo genético para um modelo específico em todos os folds\"\"\"\n",
    "    fold_results = []\n",
    "    all_selected_features = []\n",
    "\n",
    "    for fold_idx, (X_train, X_test, y_train, y_test) in enumerate(folds_data):\n",
    "        # Executar GA para este fold\n",
    "        selected_features, best_fitness, _ = run_genetic_algorithm_for_model(\n",
    "            model, X_train, X_test, y_train, y_test\n",
    "        )\n",
    "\n",
    "        fold_results.append(\n",
    "            {\"fold_idx\": fold_idx, \"auc\": best_fitness, \"features\": selected_features}\n",
    "        )\n",
    "\n",
    "        all_selected_features.append(selected_features)\n",
    "\n",
    "    # Calcular média e desvio padrão de AUC\n",
    "    aucs = [result[\"auc\"] for result in fold_results]\n",
    "    mean_auc = np.mean(aucs)\n",
    "    std_auc = np.std(aucs)\n",
    "\n",
    "    # Encontrar as features mais comuns entre todos os folds\n",
    "    # Vamos contar quantas vezes cada feature aparece\n",
    "    feature_counts = {}\n",
    "    for features in all_selected_features:\n",
    "        for feature in features:\n",
    "            if feature in feature_counts:\n",
    "                feature_counts[feature] += 1\n",
    "            else:\n",
    "                feature_counts[feature] = 1\n",
    "\n",
    "    # Ordenar features por frequência\n",
    "    sorted_features = sorted(feature_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Pegar as top MAX_FEATURES mais frequentes\n",
    "    common_features = [feature for feature, count in sorted_features[:MAX_FEATURES]]\n",
    "\n",
    "    return {\n",
    "        \"fold_results\": fold_results,\n",
    "        \"mean_auc\": mean_auc,\n",
    "        \"std_auc\": std_auc,\n",
    "        \"common_features\": common_features,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyCgeXZOkdAY"
   },
   "source": [
    "## Funções de Seleção das Melhores Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W9rJvni-kbR1"
   },
   "outputs": [],
   "source": [
    "# 5. Avaliar todas as features para um modelo específico\n",
    "def evaluate_all_features_for_model(model, folds_data):\n",
    "    \"\"\"Avalia todas as features para um modelo específico em todos os folds\"\"\"\n",
    "    fold_aucs = []\n",
    "\n",
    "    for fold_idx, (X_train, X_test, y_train, y_test) in enumerate(folds_data):\n",
    "        # Usar todas as features\n",
    "        all_features = X_train.columns\n",
    "\n",
    "        # Avaliar com o modelo específico\n",
    "        auc = evaluate_features_with_model(\n",
    "            model, X_train, X_test, y_train, y_test, all_features\n",
    "        )\n",
    "        fold_aucs.append(auc)\n",
    "\n",
    "    # Calcular média e desvio padrão dos AUCs nos folds\n",
    "    mean_auc = np.mean(fold_aucs)\n",
    "    std_auc = np.std(fold_aucs)\n",
    "\n",
    "    return {\n",
    "        \"fold_aucs\": fold_aucs,\n",
    "        \"mean_auc\": mean_auc,\n",
    "        \"std_auc\": std_auc,\n",
    "        \"features\": all_features,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkDsrtd3kvoi"
   },
   "source": [
    "## Avaliação das Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p6GmoWTyksHh"
   },
   "outputs": [],
   "source": [
    "def evaluate_all_models_with_all_feature_selection_methods(folds_data):\n",
    "    \"\"\"\n",
    "    Avalia todos os modelos usando diferentes métodos de seleção de features\n",
    "\n",
    "    Args:\n",
    "        folds_data: Lista de tuplas (X_train, X_test, y_train, y_test) para cada fold\n",
    "\n",
    "    Returns:\n",
    "        dict: Resultados por modelo e método de seleção de features\n",
    "    \"\"\"\n",
    "    # Obter a lista de modelos\n",
    "    model_dict = get_model_dict()\n",
    "\n",
    "    # Dicionário para armazenar resultados\n",
    "    results = {}\n",
    "\n",
    "    # Valores de k para ANOVA\n",
    "    k_values = range(7, 15)  # 7 a 14 features\n",
    "\n",
    "    # Avaliar cada modelo\n",
    "    for model_name, model in tqdm(model_dict.items(), desc=\"Avaliando modelos\"):\n",
    "        print(f\"\\n===== Avaliando {model_name} =====\")\n",
    "        model_results = {}\n",
    "\n",
    "        # 1. Avaliar com todas as features\n",
    "        print(\"Avaliando com todas as features...\")\n",
    "        all_features_results = evaluate_all_features_for_model(model, folds_data)\n",
    "        model_results[\"all_features\"] = all_features_results\n",
    "        print(\n",
    "            f\"  AUC médio: {all_features_results['mean_auc']:.4f} ± {all_features_results['std_auc']:.4f}\"\n",
    "        )\n",
    "\n",
    "        # 2. Avaliar com ANOVA\n",
    "        print(\"Avaliando com seleção ANOVA...\")\n",
    "        anova_results, best_k = evaluate_anova_for_model(model, folds_data, k_values)\n",
    "        model_results[\"anova\"] = {\n",
    "            \"all_k_results\": anova_results,\n",
    "            \"best_k\": best_k,\n",
    "            \"best_results\": anova_results[best_k],\n",
    "        }\n",
    "        print(f\"  Melhor k: {best_k}\")\n",
    "        print(\n",
    "            f\"  AUC médio: {anova_results[best_k]['mean_auc']:.4f} ± {anova_results[best_k]['std_auc']:.4f}\"\n",
    "        )\n",
    "        print(f\"  Features: {', '.join(anova_results[best_k]['features'])}\")\n",
    "\n",
    "        # 3. Avaliar com Algoritmo Genético\n",
    "        print(\"Avaliando com Algoritmo Genético...\")\n",
    "        ga_results = evaluate_ga_for_model(model, folds_data)\n",
    "        model_results[\"ga\"] = ga_results\n",
    "        print(\n",
    "            f\"  AUC médio: {ga_results['mean_auc']:.4f} ± {ga_results['std_auc']:.4f}\"\n",
    "        )\n",
    "        print(f\"  Features comuns: {', '.join(ga_results['common_features'])}\")\n",
    "\n",
    "        # Armazenar resultados do modelo\n",
    "        results[model_name] = model_results\n",
    "\n",
    "        # Salvar resultados parciais (após cada modelo)\n",
    "        save_results(results, \"feature_selection_results.pkl\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def save_results(results, filename):\n",
    "    \"\"\"Salva os resultados em um arquivo pickle\"\"\"\n",
    "    with open(filename, \"wb\") as f:\n",
    "        pickle.dump(results, f)\n",
    "    print(f\"Resultados salvos em {filename}\")\n",
    "\n",
    "\n",
    "def load_results(filename):\n",
    "    \"\"\"Carrega os resultados de um arquivo pickle\"\"\"\n",
    "    with open(filename, \"rb\") as f:\n",
    "        results = pickle.load(f)\n",
    "    return results\n",
    "\n",
    "\n",
    "def save_best_features_to_txt(results, filename=\"best_features.txt\"):\n",
    "    \"\"\"\n",
    "    Salva as melhores features e AUC-ROC para cada algoritmo em um arquivo texto\n",
    "\n",
    "    Args:\n",
    "        results: Dicionário com resultados por modelo e método de seleção\n",
    "        filename: Nome do arquivo de saída\n",
    "    \"\"\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"MELHORES FEATURES E AUC-ROC POR ALGORITMO\\n\")\n",
    "        f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "\n",
    "        for model_name, model_results in results.items():\n",
    "            f.write(f\"Modelo: {model_name}\\n\")\n",
    "            f.write(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "            # Todas as features\n",
    "            all_features_auc = model_results[\"all_features\"][\"mean_auc\"]\n",
    "            all_features_std = model_results[\"all_features\"][\"std_auc\"]\n",
    "            all_features_list = model_results[\"all_features\"][\"features\"]\n",
    "\n",
    "            f.write(f\"Todas as Features ({len(all_features_list)}):\\n\")\n",
    "            f.write(f\"  AUC-ROC: {all_features_auc:.4f} ± {all_features_std:.4f}\\n\")\n",
    "            f.write(f\"  Features: {', '.join(all_features_list)}\\n\\n\")\n",
    "\n",
    "            # ANOVA\n",
    "            best_k = model_results[\"anova\"][\"best_k\"]\n",
    "            anova_auc = model_results[\"anova\"][\"best_results\"][\"mean_auc\"]\n",
    "            anova_std = model_results[\"anova\"][\"best_results\"][\"std_auc\"]\n",
    "            anova_features = model_results[\"anova\"][\"best_results\"][\"features\"]\n",
    "\n",
    "            f.write(f\"ANOVA (k={best_k}):\\n\")\n",
    "            f.write(f\"  AUC-ROC: {anova_auc:.4f} ± {anova_std:.4f}\\n\")\n",
    "            f.write(f\"  Features: {', '.join(anova_features)}\\n\\n\")\n",
    "\n",
    "            # Algoritmo Genético\n",
    "            ga_auc = model_results[\"ga\"][\"mean_auc\"]\n",
    "            ga_std = model_results[\"ga\"][\"std_auc\"]\n",
    "            ga_features = model_results[\"ga\"][\"common_features\"]\n",
    "\n",
    "            f.write(f\"Algoritmo Genético:\\n\")\n",
    "            f.write(f\"  AUC-ROC: {ga_auc:.4f} ± {ga_std:.4f}\\n\")\n",
    "            f.write(f\"  Features: {', '.join(ga_features)}\\n\\n\")\n",
    "\n",
    "            # Determinar o melhor método\n",
    "            best_auc = max(all_features_auc, anova_auc, ga_auc)\n",
    "\n",
    "            if best_auc == all_features_auc:\n",
    "                best_method = \"Todas as Features\"\n",
    "                best_features = all_features_list\n",
    "            elif best_auc == anova_auc:\n",
    "                best_method = f\"ANOVA (k={best_k})\"\n",
    "                best_features = anova_features\n",
    "            else:\n",
    "                best_method = \"Algoritmo Genético\"\n",
    "                best_features = ga_features\n",
    "\n",
    "            f.write(f\"MELHOR MÉTODO: {best_method}\\n\")\n",
    "            f.write(f\"  AUC-ROC: {best_auc:.4f}\\n\")\n",
    "            f.write(f\"  Features: {', '.join(best_features)}\\n\\n\")\n",
    "\n",
    "            f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "\n",
    "    print(f\"Informações das melhores features salvas em {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zqAOOyd_fK1h"
   },
   "source": [
    "## Visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CUNCx04gfK1h"
   },
   "outputs": [],
   "source": [
    "def create_comparison_plots(results):\n",
    "    \"\"\"\n",
    "    Cria box plots comparando os diferentes métodos de seleção de features para cada modelo\n",
    "\n",
    "    Args:\n",
    "        results: Dicionário com resultados por modelo e método de seleção\n",
    "    \"\"\"\n",
    "    # Criar diretório para salvar os gráficos\n",
    "    os.makedirs(\"comparison_plots\", exist_ok=True)\n",
    "\n",
    "    # Dicionário para armazenar todos os dados para um gráfico comparativo final\n",
    "    all_comparison_data = []\n",
    "\n",
    "    # Para cada modelo\n",
    "    for model_name, model_results in results.items():\n",
    "        # Dados para o box plot\n",
    "        comparison_data = {\"Método\": [], \"AUC-ROC\": []}\n",
    "\n",
    "        # Adicionar dados de todos os folds para cada método\n",
    "\n",
    "        # Todas as features\n",
    "        method_name = \"Todas as Features\"\n",
    "        fold_aucs = model_results[\"all_features\"][\"fold_aucs\"]\n",
    "        for auc in fold_aucs:\n",
    "            comparison_data[\"Método\"].append(method_name)\n",
    "            comparison_data[\"AUC-ROC\"].append(auc)\n",
    "            all_comparison_data.append(\n",
    "                {\"Modelo\": model_name, \"Método\": method_name, \"AUC-ROC\": auc}\n",
    "            )\n",
    "\n",
    "        # ANOVA\n",
    "        method_name = f\"ANOVA (k={model_results['anova']['best_k']})\"\n",
    "        fold_aucs = model_results[\"anova\"][\"best_results\"][\"fold_aucs\"]\n",
    "        for auc in fold_aucs:\n",
    "            comparison_data[\"Método\"].append(method_name)\n",
    "            comparison_data[\"AUC-ROC\"].append(auc)\n",
    "            all_comparison_data.append(\n",
    "                {\"Modelo\": model_name, \"Método\": \"ANOVA\", \"AUC-ROC\": auc}\n",
    "            )\n",
    "\n",
    "        # Algoritmo Genético\n",
    "        method_name = \"Algoritmo Genético\"\n",
    "        fold_aucs = [result[\"auc\"] for result in model_results[\"ga\"][\"fold_results\"]]\n",
    "        for auc in fold_aucs:\n",
    "            comparison_data[\"Método\"].append(method_name)\n",
    "            comparison_data[\"AUC-ROC\"].append(auc)\n",
    "            all_comparison_data.append(\n",
    "                {\"Modelo\": model_name, \"Método\": method_name, \"AUC-ROC\": auc}\n",
    "            )\n",
    "\n",
    "        # Criar DataFrame\n",
    "        df_comparison = pd.DataFrame(comparison_data)\n",
    "\n",
    "        # Criar box plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        ax = sns.boxplot(x=\"Método\", y=\"AUC-ROC\", data=df_comparison, palette=\"Set2\")\n",
    "\n",
    "        # Adicionar pontos individuais\n",
    "        sns.stripplot(\n",
    "            x=\"Método\",\n",
    "            y=\"AUC-ROC\",\n",
    "            data=df_comparison,\n",
    "            size=4,\n",
    "            color=\"black\",\n",
    "            alpha=0.5,\n",
    "        )\n",
    "\n",
    "        # Ajustar elementos visuais\n",
    "        plt.title(\n",
    "            f\"Comparação de Métodos de Seleção de Features para {model_name}\",\n",
    "            fontsize=14,\n",
    "        )\n",
    "        plt.ylabel(\"AUC-ROC\", fontsize=12)\n",
    "        plt.xlabel(\"Método de Seleção\", fontsize=12)\n",
    "        plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "        plt.ylim(0.5, 1.0)\n",
    "\n",
    "        # Adicionar médias de cada método\n",
    "        for i, method in enumerate(df_comparison[\"Método\"].unique()):\n",
    "            mean_auc = df_comparison[df_comparison[\"Método\"] == method][\n",
    "                \"AUC-ROC\"\n",
    "            ].mean()\n",
    "            ax.text(i, 0.52, f\"Média: {mean_auc:.4f}\", ha=\"center\", fontsize=10)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\n",
    "            f'comparison_plots/{model_name.replace(\" \", \"_\")}_comparison.png', dpi=300\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "    # Criar DataFrame com todos os dados para comparação final\n",
    "    df_all = pd.DataFrame(all_comparison_data)\n",
    "\n",
    "    # Criar um heatmap para comparar todos os modelos e métodos\n",
    "    plt.figure(figsize=(14, 10))\n",
    "\n",
    "    # Calcular médias por modelo e método\n",
    "    pivot_table = df_all.pivot_table(\n",
    "        index=\"Modelo\", columns=\"Método\", values=\"AUC-ROC\", aggfunc=\"mean\"\n",
    "    )\n",
    "\n",
    "    # Criar heatmap\n",
    "    sns.heatmap(\n",
    "        pivot_table,\n",
    "        annot=True,\n",
    "        fmt=\".4f\",\n",
    "        cmap=\"YlGnBu\",\n",
    "        vmin=0.5,\n",
    "        vmax=1.0,\n",
    "        linewidths=0.5,\n",
    "        cbar_kws={\"label\": \"AUC-ROC médio\"},\n",
    "    )\n",
    "    plt.title(\n",
    "        \"Comparação de AUC-ROC por Modelo e Método de Seleção de Features\", fontsize=16\n",
    "    )\n",
    "    plt.ylabel(\"Modelo\", fontsize=14)\n",
    "    plt.xlabel(\"Método de Seleção de Features\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"comparison_plots/all_models_comparison_heatmap.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # Criar um gráfico de barras para comparar o melhor método por modelo\n",
    "    best_methods = []\n",
    "    for model_name, model_results in results.items():\n",
    "        # Obter AUC para cada método\n",
    "        all_features_auc = model_results[\"all_features\"][\"mean_auc\"]\n",
    "        anova_auc = model_results[\"anova\"][\"best_results\"][\"mean_auc\"]\n",
    "        ga_auc = model_results[\"ga\"][\"mean_auc\"]\n",
    "\n",
    "        # Determinar o melhor método\n",
    "        methods = [\"Todas as Features\", \"ANOVA\", \"Algoritmo Genético\"]\n",
    "        aucs = [all_features_auc, anova_auc, ga_auc]\n",
    "        best_idx = np.argmax(aucs)\n",
    "        best_methods.append(\n",
    "            {\n",
    "                \"Modelo\": model_name,\n",
    "                \"Melhor Método\": methods[best_idx],\n",
    "                \"AUC-ROC\": aucs[best_idx],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Criar DataFrame\n",
    "    df_best = pd.DataFrame(best_methods)\n",
    "\n",
    "    # Criar gráfico de barras\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    bars = plt.bar(df_best[\"Modelo\"], df_best[\"AUC-ROC\"], color=\"skyblue\")\n",
    "\n",
    "    # Adicionar texto para cada barra indicando o melhor método\n",
    "    for i, (bar, method) in enumerate(zip(bars, df_best[\"Melhor Método\"])):\n",
    "        height = bar.get_height()\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2.0,\n",
    "            height + 0.01,\n",
    "            method,\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            rotation=0,\n",
    "            fontsize=10,\n",
    "        )\n",
    "\n",
    "    plt.title(\"Melhor Método de Seleção de Features por Modelo\", fontsize=16)\n",
    "    plt.ylabel(\"AUC-ROC\", fontsize=14)\n",
    "    plt.xlabel(\"Modelo\", fontsize=14)\n",
    "    plt.ylim(0.5, 1.0)\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"comparison_plots/best_methods_by_model.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Gráficos de comparação gerados e salvos na pasta 'comparison_plots'\")\n",
    "\n",
    "\n",
    "def create_summary_table(results):\n",
    "    \"\"\"\n",
    "    Cria uma tabela resumo comparando os diferentes métodos de seleção de features\n",
    "\n",
    "    Args:\n",
    "        results: Dicionário com resultados por modelo e método de seleção\n",
    "    \"\"\"\n",
    "    # Dados para a tabela\n",
    "    table_data = []\n",
    "\n",
    "    for model_name, model_results in results.items():\n",
    "        # Obter dados de cada método\n",
    "        all_features_auc = model_results[\"all_features\"][\"mean_auc\"]\n",
    "        all_features_std = model_results[\"all_features\"][\"std_auc\"]\n",
    "        all_features_count = len(model_results[\"all_features\"][\"features\"])\n",
    "\n",
    "        best_k = model_results[\"anova\"][\"best_k\"]\n",
    "        anova_auc = model_results[\"anova\"][\"best_results\"][\"mean_auc\"]\n",
    "        anova_std = model_results[\"anova\"][\"best_results\"][\"std_auc\"]\n",
    "        anova_count = len(model_results[\"anova\"][\"best_results\"][\"features\"])\n",
    "\n",
    "        ga_auc = model_results[\"ga\"][\"mean_auc\"]\n",
    "        ga_std = model_results[\"ga\"][\"std_auc\"]\n",
    "        ga_count = len(model_results[\"ga\"][\"common_features\"])\n",
    "\n",
    "        # Determinar o melhor método\n",
    "        methods = [\"Todas as Features\", f\"ANOVA (k={best_k})\", \"Algoritmo Genético\"]\n",
    "        aucs = [all_features_auc, anova_auc, ga_auc]\n",
    "        best_idx = np.argmax(aucs)\n",
    "        best_method = methods[best_idx]\n",
    "\n",
    "        # Adicionar à tabela\n",
    "        table_data.append(\n",
    "            {\n",
    "                \"Modelo\": model_name,\n",
    "                \"Todas Features AUC\": f\"{all_features_auc:.4f} ± {all_features_std:.4f}\",\n",
    "                \"Todas Features #\": all_features_count,\n",
    "                \"ANOVA AUC\": f\"{anova_auc:.4f} ± {anova_std:.4f}\",\n",
    "                \"ANOVA #\": anova_count,\n",
    "                \"GA AUC\": f\"{ga_auc:.4f} ± {ga_std:.4f}\",\n",
    "                \"GA #\": ga_count,\n",
    "                \"Melhor Método\": best_method,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Criar DataFrame\n",
    "    df_summary = pd.DataFrame(table_data)\n",
    "\n",
    "    # Salvar como CSV\n",
    "    df_summary.to_csv(\"comparison_summary.csv\", index=False)\n",
    "\n",
    "    # Exibir tabela\n",
    "    print(df_summary)\n",
    "    print(\"\\nTabela resumo salva em 'comparison_summary.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yv6FR21Z5HOq",
    "outputId": "e02aab57-b9fc-43ba-c8e0-ddb051ae3597"
   },
   "outputs": [],
   "source": [
    "# DEBUG\n",
    "# for i,data in enumerate(smote_folds_data):\n",
    "#     print(f\"Fold {i+1}:\")\n",
    "#     print(type(data[0]), type(data[1]), type(data[2]), type(data[3]))\n",
    "#     print(data[0].shape, data[1].shape, data[2].shape, data[3].shape)\n",
    "#     print(data[0].info())\n",
    "#     print(data[1].info())\n",
    "#     print(set(data[2]))\n",
    "#     print(set(data[3]))\n",
    "#     print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rlnaaEHSlDGf",
    "outputId": "281885b2-e033-426c-8940-ac86ae2b207e"
   },
   "outputs": [],
   "source": [
    "def search_best_features():\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        print(\"===== INICIANDO O PROCESSO DE SELEÇÃO DE FEATURES =====\")\n",
    "        # Executar a avaliação dos modelos\n",
    "        print(\"\\nAvaliando modelos com diferentes métodos de seleção de features...\")\n",
    "        results_smote = evaluate_all_models_with_all_feature_selection_methods(\n",
    "            smote_folds_data\n",
    "        )\n",
    "        results_original = evaluate_all_models_with_all_feature_selection_methods(\n",
    "            original_folds_data\n",
    "        )\n",
    "\n",
    "        # Salvar as melhores features em um arquivo texto\n",
    "        print(\"\\nSalvando as melhores features para cada algoritmo...\")\n",
    "        save_best_features_to_txt(results_smote, \"best_features_smote.txt\")\n",
    "        save_best_features_to_txt(results_original, \"best_features_original.txt\")\n",
    "\n",
    "        # Exibir tempo de execução\n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "        hours, remainder = divmod(total_time, 3600)\n",
    "        minutes, seconds = divmod(remainder, 60)\n",
    "\n",
    "        print(\"\\n===== PROCESSO CONCLUÍDO =====\")\n",
    "        print(f\"Tempo total de execução: {int(hours)}h {int(minutes)}m {int(seconds)}s\")\n",
    "        return results_smote, results_original\n",
    "    except Exception as e:\n",
    "        print(f\"\\nErro durante a execução: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_original, results_smote = search_best_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nmU8edYMyCIX",
    "outputId": "e3c92bf0-462c-42e2-9140-bd13bd2d3387"
   },
   "outputs": [],
   "source": [
    "print(\"===== RESULTADOS com treinamento sem SMOTE=====\")\n",
    "print(results_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5yurddhjtDGH",
    "outputId": "f59b2449-bafe-4c22-8917-95265046a662"
   },
   "outputs": [],
   "source": [
    "print(\"===== RESULTADOS com treinamento com SMOTE=====\")\n",
    "print(results_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4mnFUtLyZD9"
   },
   "source": [
    "# 4. Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LtdFB-fXy7Hx"
   },
   "source": [
    "Nesta seção utilizaremos Optuna para encontrar os melhores hiperparametros para os modelos abaixo utilizando Optune:\n",
    "\n",
    "\n",
    "\n",
    "1. Decision Trees\n",
    "2. Gradient Tree Boosting\n",
    "3. k-Nearest Neighbors\n",
    "4. LightGBM\n",
    "5. Multinomial Logistic Regression\n",
    "6. Naive Bayes\n",
    "7. Neural Networks\n",
    "8. Random Forests\n",
    "9. Support Vector Machines\n",
    "10. XGBoost\n",
    "11. CatBoost\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-Eq9rsvvy43"
   },
   "source": [
    "## Função para uso do melhor fold para cada Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gYyZo8iIt8AN"
   },
   "outputs": [],
   "source": [
    "def create_optimized_model_folds(original_folds_data, smote_folds_data):\n",
    "    \"\"\"\n",
    "    Cria folds otimizados para cada modelo usando as melhores features e dataset (original ou SMOTE)\n",
    "\n",
    "    Args:\n",
    "        original_folds_data: Lista de tuplas (X_train, X_test, y_train, y_test) do dataset original\n",
    "        smote_folds_data: Lista de tuplas (X_train, X_test, y_train, y_test) do dataset com SMOTE\n",
    "\n",
    "    Returns:\n",
    "        Dict: Dicionário onde cada chave é um modelo e o valor é um dicionário com seus folds otimizados\n",
    "    \"\"\"\n",
    "    # Informações dos melhores modelos a partir da análise\n",
    "    best_models = {\n",
    "        \"Decision Trees\": {\n",
    "            \"dataset\": \"original\",\n",
    "            \"method\": \"Algoritmo Genético\",\n",
    "            \"auc\": 0.6682,\n",
    "            \"features\": [\n",
    "                \"Stress_Keeps_Patient_from_Sleeping\",\n",
    "                \"Dental_Health\",\n",
    "                \"Medication_Keeps_Patient_from_Sleeping\",\n",
    "                \"Race\",\n",
    "                \"Physical_Health\",\n",
    "                \"Prescription_Sleep_Medication\",\n",
    "                \"Employment\",\n",
    "                \"Bathroom_Needs_Keeps_Patient_from_Sleeping\",\n",
    "                \"Trouble_Sleeping\",\n",
    "                \"Age\",\n",
    "                \"Gender\",\n",
    "                \"Uknown_Keeps_Patient_from_Sleeping\",\n",
    "                \"Mental_Health\",\n",
    "                \"Pain_Keeps_Patient_from_Sleeping\",\n",
    "            ],\n",
    "        },\n",
    "        \"Gradient Tree Boosting\": {\n",
    "            \"dataset\": \"original\",\n",
    "            \"method\": \"Algoritmo Genético\",\n",
    "            \"auc\": 0.6588,\n",
    "            \"features\": [\n",
    "                \"Race\",\n",
    "                \"Medication_Keeps_Patient_from_Sleeping\",\n",
    "                \"Uknown_Keeps_Patient_from_Sleeping\",\n",
    "                \"Physical_Health\",\n",
    "                \"Dental_Health\",\n",
    "                \"Employment\",\n",
    "                \"Stress_Keeps_Patient_from_Sleeping\",\n",
    "                \"Pain_Keeps_Patient_from_Sleeping\",\n",
    "                \"Bathroom_Needs_Keeps_Patient_from_Sleeping\",\n",
    "                \"Age\",\n",
    "                \"Mental_Health\",\n",
    "                \"Gender\",\n",
    "                \"Prescription_Sleep_Medication\",\n",
    "                \"Trouble_Sleeping\",\n",
    "            ],\n",
    "        },\n",
    "        \"k-Nearest Neighbors\": {\n",
    "            \"dataset\": \"original\",\n",
    "            \"method\": \"Algoritmo Genético\",\n",
    "            \"auc\": 0.6488,\n",
    "            \"features\": [\n",
    "                \"Physical_Health\",\n",
    "                \"Prescription_Sleep_Medication\",\n",
    "                \"Stress_Keeps_Patient_from_Sleeping\",\n",
    "                \"Age\",\n",
    "                \"Mental_Health\",\n",
    "                \"Race\",\n",
    "                \"Medication_Keeps_Patient_from_Sleeping\",\n",
    "                \"Uknown_Keeps_Patient_from_Sleeping\",\n",
    "                \"Pain_Keeps_Patient_from_Sleeping\",\n",
    "                \"Bathroom_Needs_Keeps_Patient_from_Sleeping\",\n",
    "                \"Employment\",\n",
    "                \"Gender\",\n",
    "                \"Dental_Health\",\n",
    "                \"Trouble_Sleeping\",\n",
    "            ],\n",
    "        },\n",
    "        \"LightGBM\": {\n",
    "            \"dataset\": \"smote\",\n",
    "            \"method\": \"Algoritmo Genético\",\n",
    "            \"auc\": 0.6467,\n",
    "            \"features\": [\n",
    "                \"Prescription_Sleep_Medication\",\n",
    "                \"Race\",\n",
    "                \"Age\",\n",
    "                \"Employment\",\n",
    "                \"Pain_Keeps_Patient_from_Sleeping\",\n",
    "                \"Dental_Health\",\n",
    "                \"Medication_Keeps_Patient_from_Sleeping\",\n",
    "                \"Stress_Keeps_Patient_from_Sleeping\",\n",
    "                \"Uknown_Keeps_Patient_from_Sleeping\",\n",
    "                \"Bathroom_Needs_Keeps_Patient_from_Sleeping\",\n",
    "                \"Physical_Health\",\n",
    "                \"Mental_Health\",\n",
    "                \"Gender\",\n",
    "                \"Trouble_Sleeping\",\n",
    "            ],\n",
    "        },\n",
    "        \"Multinomial Logistic Regression\": {\n",
    "            \"dataset\": \"original\",\n",
    "            \"method\": \"Algoritmo Genético\",\n",
    "            \"auc\": 0.6549,\n",
    "            \"features\": [\n",
    "                \"Dental_Health\",\n",
    "                \"Stress_Keeps_Patient_from_Sleeping\",\n",
    "                \"Medication_Keeps_Patient_from_Sleeping\",\n",
    "                \"Bathroom_Needs_Keeps_Patient_from_Sleeping\",\n",
    "                \"Prescription_Sleep_Medication\",\n",
    "                \"Race\",\n",
    "                \"Physical_Health\",\n",
    "                \"Age\",\n",
    "                \"Mental_Health\",\n",
    "                \"Pain_Keeps_Patient_from_Sleeping\",\n",
    "                \"Trouble_Sleeping\",\n",
    "                \"Gender\",\n",
    "                \"Uknown_Keeps_Patient_from_Sleeping\",\n",
    "                \"Employment\",\n",
    "            ],\n",
    "        },\n",
    "        \"Naive Bayes\": {\n",
    "            \"dataset\": \"original\",\n",
    "            \"method\": \"Algoritmo Genético\",\n",
    "            \"auc\": 0.6579,\n",
    "            \"features\": [\n",
    "                \"Prescription_Sleep_Medication\",\n",
    "                \"Medication_Keeps_Patient_from_Sleeping\",\n",
    "                \"Dental_Health\",\n",
    "                \"Age\",\n",
    "                \"Trouble_Sleeping\",\n",
    "                \"Bathroom_Needs_Keeps_Patient_from_Sleeping\",\n",
    "                \"Employment\",\n",
    "                \"Gender\",\n",
    "                \"Physical_Health\",\n",
    "                \"Mental_Health\",\n",
    "                \"Stress_Keeps_Patient_from_Sleeping\",\n",
    "                \"Race\",\n",
    "                \"Pain_Keeps_Patient_from_Sleeping\",\n",
    "                \"Uknown_Keeps_Patient_from_Sleeping\",\n",
    "            ],\n",
    "        },\n",
    "        \"Random Forests\": {\n",
    "            \"dataset\": \"original\",\n",
    "            \"method\": \"Algoritmo Genético\",\n",
    "            \"auc\": 0.6604,\n",
    "            \"features\": [\n",
    "                \"Dental_Health\",\n",
    "                \"Medication_Keeps_Patient_from_Sleeping\",\n",
    "                \"Physical_Health\",\n",
    "                \"Race\",\n",
    "                \"Prescription_Sleep_Medication\",\n",
    "                \"Employment\",\n",
    "                \"Pain_Keeps_Patient_from_Sleeping\",\n",
    "                \"Bathroom_Needs_Keeps_Patient_from_Sleeping\",\n",
    "                \"Stress_Keeps_Patient_from_Sleeping\",\n",
    "                \"Age\",\n",
    "                \"Uknown_Keeps_Patient_from_Sleeping\",\n",
    "                \"Mental_Health\",\n",
    "                \"Trouble_Sleeping\",\n",
    "                \"Gender\",\n",
    "            ],\n",
    "        },\n",
    "        \"Support Vector Machines\": {\n",
    "            \"dataset\": \"smote\",\n",
    "            \"method\": \"Algoritmo Genético\",\n",
    "            \"auc\": 0.6499,\n",
    "            \"features\": [\n",
    "                \"Physical_Health\",\n",
    "                \"Employment\",\n",
    "                \"Pain_Keeps_Patient_from_Sleeping\",\n",
    "                \"Prescription_Sleep_Medication\",\n",
    "                \"Dental_Health\",\n",
    "                \"Race\",\n",
    "                \"Stress_Keeps_Patient_from_Sleeping\",\n",
    "                \"Medication_Keeps_Patient_from_Sleeping\",\n",
    "                \"Age\",\n",
    "                \"Gender\",\n",
    "                \"Uknown_Keeps_Patient_from_Sleeping\",\n",
    "                \"Trouble_Sleeping\",\n",
    "                \"Bathroom_Needs_Keeps_Patient_from_Sleeping\",\n",
    "                \"Mental_Health\",\n",
    "            ],\n",
    "        },\n",
    "        \"XGBoost\": {\n",
    "            \"dataset\": \"smote\",\n",
    "            \"method\": \"Algoritmo Genético\",\n",
    "            \"auc\": 0.6559,\n",
    "            \"features\": [\n",
    "                \"Dental_Health\",\n",
    "                \"Medication_Keeps_Patient_from_Sleeping\",\n",
    "                \"Race\",\n",
    "                \"Prescription_Sleep_Medication\",\n",
    "                \"Physical_Health\",\n",
    "                \"Employment\",\n",
    "                \"Pain_Keeps_Patient_from_Sleeping\",\n",
    "                \"Trouble_Sleeping\",\n",
    "                \"Uknown_Keeps_Patient_from_Sleeping\",\n",
    "                \"Gender\",\n",
    "                \"Age\",\n",
    "                \"Stress_Keeps_Patient_from_Sleeping\",\n",
    "                \"Mental_Health\",\n",
    "                \"Bathroom_Needs_Keeps_Patient_from_Sleeping\",\n",
    "            ],\n",
    "        },\n",
    "        \"CatBoost\": {\n",
    "            \"dataset\": \"smote\",\n",
    "            \"method\": \"Algoritmo Genético\",\n",
    "            \"auc\": 0.6465,\n",
    "            \"features\": [\n",
    "                \"Prescription_Sleep_Medication\",\n",
    "                \"Physical_Health\",\n",
    "                \"Age\",\n",
    "                \"Employment\",\n",
    "                \"Stress_Keeps_Patient_from_Sleeping\",\n",
    "                \"Medication_Keeps_Patient_from_Sleeping\",\n",
    "                \"Uknown_Keeps_Patient_from_Sleeping\",\n",
    "                \"Race\",\n",
    "                \"Bathroom_Needs_Keeps_Patient_from_Sleeping\",\n",
    "                \"Pain_Keeps_Patient_from_Sleeping\",\n",
    "                \"Trouble_Sleeping\",\n",
    "                \"Mental_Health\",\n",
    "                \"Gender\",\n",
    "                \"Dental_Health\",\n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # Combinar os folds em um dicionário\n",
    "    folds_data = {\"original\": original_folds_data, \"smote\": smote_folds_data}\n",
    "\n",
    "    # Criar dicionário para armazenar os folds otimizados por modelo\n",
    "    optimized_folds = {}\n",
    "\n",
    "    # Para cada modelo, criar seus folds otimizados\n",
    "    for model_name, model_info in best_models.items():\n",
    "        # Determinar qual conjunto de folds usar\n",
    "        dataset_type = model_info[\"dataset\"]\n",
    "        selected_folds = folds_data[dataset_type]\n",
    "\n",
    "        # Features selecionadas para este modelo\n",
    "        features = model_info[\"features\"]\n",
    "\n",
    "        # Criar folds otimizados\n",
    "        model_folds = []\n",
    "\n",
    "        for i, (X_train, X_test, y_train, y_test) in enumerate(selected_folds):\n",
    "            # Filtrar apenas as features selecionadas\n",
    "            X_train_filtered = X_train[features].copy()\n",
    "            X_test_filtered = X_test[features].copy()\n",
    "\n",
    "            # Verificar as distribuições de classes\n",
    "            if (\n",
    "                i == 0\n",
    "            ):  # Mostrar apenas para o primeiro fold para não sobrecarregar a saída\n",
    "                print(f\"\\nModelo: {model_name}\")\n",
    "                print(f\"Dataset: {dataset_type}\")\n",
    "                print(f\"Features selecionadas ({len(features)}): {', '.join(features)}\")\n",
    "                print(f\"Distribuição de classes em y_train: {Counter(y_train)}\")\n",
    "                print(f\"Distribuição de classes em y_test: {Counter(y_test)}\")\n",
    "                print(f\"Dimensões de X_train: {X_train_filtered.shape}\")\n",
    "                print(f\"Dimensões de X_test: {X_test_filtered.shape}\")\n",
    "\n",
    "            # Adicionar o fold filtrado\n",
    "            model_folds.append((X_train_filtered, X_test_filtered, y_train, y_test))\n",
    "\n",
    "        # Armazenar informações completas para este modelo\n",
    "        optimized_folds[model_name] = {\n",
    "            \"folds\": model_folds,\n",
    "            \"features\": features,\n",
    "            \"dataset_type\": dataset_type,\n",
    "            \"auc\": model_info[\"auc\"],\n",
    "            \"method\": model_info[\"method\"],\n",
    "        }\n",
    "\n",
    "    # Resumo das configurações ótimas por modelo\n",
    "    print(\"\\n=== RESUMO DAS CONFIGURAÇÕES ÓTIMAS POR MODELO ===\")\n",
    "    for model_name, model_data in optimized_folds.items():\n",
    "        print(f\"{model_name}:\")\n",
    "        print(f\"  Dataset: {model_data['dataset_type']}\")\n",
    "        print(f\"  Método: {model_data['method']}\")\n",
    "        print(f\"  AUC: {model_data['auc']:.4f}\")\n",
    "        print(f\"  Número de features: {len(model_data['features'])}\")\n",
    "\n",
    "    return optimized_folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YrL91TA_v5p0"
   },
   "source": [
    "## Funções Objetivo para busca de hiperparâmetro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LSpVOZkT4I9C"
   },
   "outputs": [],
   "source": [
    "# Funções objetivo adaptadas para usar folds otimizados (sem mapeamento de classes)\n",
    "def objective_dt(trial, model_folds):\n",
    "    \"\"\"Função objetivo para Decision Trees usando folds otimizados\"\"\"\n",
    "    param = {\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 30),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "        \"criterion\": trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    "\n",
    "    # Avaliação usando os folds otimizados\n",
    "    auc_scores = []\n",
    "    for X_train, X_test, y_train, y_test in model_folds:\n",
    "        model = DecisionTreeClassifier(**param)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Calcular AUC\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_prob = model.predict_proba(X_test)\n",
    "            auc = roc_auc_score(y_test, y_prob, multi_class=\"ovr\", average=\"macro\")\n",
    "            auc_scores.append(auc)\n",
    "\n",
    "    return np.mean(auc_scores)\n",
    "\n",
    "\n",
    "def objective_gb(trial, model_folds):\n",
    "    \"\"\"Função objetivo para Gradient Boosting usando folds otimizados\"\"\"\n",
    "    param = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    "\n",
    "    # Avaliação usando os folds otimizados\n",
    "    auc_scores = []\n",
    "    for X_train, X_test, y_train, y_test in model_folds:\n",
    "        model = GradientBoostingClassifier(**param)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Calcular AUC\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_prob = model.predict_proba(X_test)\n",
    "            auc = roc_auc_score(y_test, y_prob, multi_class=\"ovr\", average=\"macro\")\n",
    "            auc_scores.append(auc)\n",
    "\n",
    "    return np.mean(auc_scores)\n",
    "\n",
    "\n",
    "def objective_knn(trial, model_folds):\n",
    "    \"\"\"Função objetivo para K-Nearest Neighbors usando folds otimizados\"\"\"\n",
    "    param = {\n",
    "        \"n_neighbors\": trial.suggest_int(\"n_neighbors\", 1, 30),\n",
    "        \"weights\": trial.suggest_categorical(\"weights\", [\"uniform\", \"distance\"]),\n",
    "        \"algorithm\": trial.suggest_categorical(\n",
    "            \"algorithm\", [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]\n",
    "        ),\n",
    "        \"p\": trial.suggest_int(\"p\", 1, 2),  # p=1: manhattan, p=2: euclidean\n",
    "    }\n",
    "\n",
    "    # Avaliação usando os folds otimizados\n",
    "    auc_scores = []\n",
    "    for X_train, X_test, y_train, y_test in model_folds:\n",
    "        model = KNeighborsClassifier(**param)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Calcular AUC\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_prob = model.predict_proba(X_test)\n",
    "            auc = roc_auc_score(y_test, y_prob, multi_class=\"ovr\", average=\"macro\")\n",
    "            auc_scores.append(auc)\n",
    "\n",
    "    return np.mean(auc_scores)\n",
    "\n",
    "\n",
    "def objective_lgbm(trial, model_folds):\n",
    "    \"\"\"Função objetivo para LightGBM usando folds otimizados\"\"\"\n",
    "    param = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 20, 100),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    "\n",
    "    # Avaliação usando os folds otimizados\n",
    "    auc_scores = []\n",
    "    for X_train, X_test, y_train, y_test in model_folds:\n",
    "        model = LGBMClassifier(**param)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Calcular AUC\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_prob = model.predict_proba(X_test)\n",
    "            auc = roc_auc_score(y_test, y_prob, multi_class=\"ovr\", average=\"macro\")\n",
    "            auc_scores.append(auc)\n",
    "\n",
    "    return np.mean(auc_scores)\n",
    "\n",
    "\n",
    "def objective_lr(trial, model_folds):\n",
    "    \"\"\"Função objetivo para Multinomial Logistic Regression usando folds otimizados\"\"\"\n",
    "    param = {\n",
    "        \"C\": trial.suggest_float(\"C\", 1e-4, 1e2, log=True),\n",
    "        \"solver\": trial.suggest_categorical(\n",
    "            \"solver\", [\"newton-cg\", \"lbfgs\", \"sag\", \"saga\"]\n",
    "        ),\n",
    "        \"max_iter\": 2000,  # fixo para garantir convergência\n",
    "        \"multi_class\": \"multinomial\",\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    "\n",
    "    # Avaliação usando os folds otimizados\n",
    "    auc_scores = []\n",
    "    for X_train, X_test, y_train, y_test in model_folds:\n",
    "        model = LogisticRegression(**param)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Calcular AUC\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_prob = model.predict_proba(X_test)\n",
    "            auc = roc_auc_score(y_test, y_prob, multi_class=\"ovr\", average=\"macro\")\n",
    "            auc_scores.append(auc)\n",
    "\n",
    "    return np.mean(auc_scores)\n",
    "\n",
    "\n",
    "def objective_nb(trial, model_folds):\n",
    "    \"\"\"Função objetivo para Naive Bayes usando folds otimizados\"\"\"\n",
    "    param = {\n",
    "        \"var_smoothing\": trial.suggest_float(\"var_smoothing\", 1e-12, 1e-2, log=True)\n",
    "    }\n",
    "\n",
    "    # Avaliação usando os folds otimizados\n",
    "    auc_scores = []\n",
    "    for X_train, X_test, y_train, y_test in model_folds:\n",
    "        model = GaussianNB(**param)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Calcular AUC\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_prob = model.predict_proba(X_test)\n",
    "            auc = roc_auc_score(y_test, y_prob, multi_class=\"ovr\", average=\"macro\")\n",
    "            auc_scores.append(auc)\n",
    "\n",
    "    return np.mean(auc_scores)\n",
    "\n",
    "\n",
    "def objective_rf(trial, model_folds):\n",
    "    \"\"\"Função objetivo para Random Forests usando folds otimizados\"\"\"\n",
    "    param = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 30),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "        \"bootstrap\": trial.suggest_categorical(\"bootstrap\", [True, False]),\n",
    "        \"criterion\": trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    "\n",
    "    # Avaliação usando os folds otimizados\n",
    "    auc_scores = []\n",
    "    for X_train, X_test, y_train, y_test in model_folds:\n",
    "        model = RandomForestClassifier(**param)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Calcular AUC\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_prob = model.predict_proba(X_test)\n",
    "            auc = roc_auc_score(y_test, y_prob, multi_class=\"ovr\", average=\"macro\")\n",
    "            auc_scores.append(auc)\n",
    "\n",
    "    return np.mean(auc_scores)\n",
    "\n",
    "\n",
    "def objective_svm(trial, model_folds):\n",
    "    \"\"\"Função objetivo para Support Vector Machines usando folds otimizados\"\"\"\n",
    "    param = {\n",
    "        \"C\": trial.suggest_float(\"C\", 1e-4, 1e2, log=True),\n",
    "        \"kernel\": trial.suggest_categorical(\n",
    "            \"kernel\", [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
    "        ),\n",
    "        \"gamma\": trial.suggest_categorical(\"gamma\", [\"scale\", \"auto\"]),\n",
    "        \"probability\": True,  # Necessário para calcular AUC\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    "\n",
    "    # Avaliação usando os folds otimizados\n",
    "    auc_scores = []\n",
    "    for X_train, X_test, y_train, y_test in model_folds:\n",
    "        model = SVC(**param)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Calcular AUC\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            y_prob = model.predict_proba(X_test)\n",
    "            auc = roc_auc_score(y_test, y_prob, multi_class=\"ovr\", average=\"macro\")\n",
    "            auc_scores.append(auc)\n",
    "\n",
    "    return np.mean(auc_scores)\n",
    "\n",
    "\n",
    "def objective_xgb(trial, model_folds):\n",
    "    \"\"\"Função objetivo para XGBoost usando folds otimizados\"\"\"\n",
    "    param = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 500),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"random_state\": 42,\n",
    "    }\n",
    "\n",
    "    # Avaliação usando os folds otimizados\n",
    "    auc_scores = []\n",
    "    for X_train, X_test, y_train, y_test in model_folds:\n",
    "        try:\n",
    "            model = XGBClassifier(**param)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Calcular AUC\n",
    "            if hasattr(model, \"predict_proba\"):\n",
    "                y_prob = model.predict_proba(X_test)\n",
    "                auc = roc_auc_score(y_test, y_prob, multi_class=\"ovr\", average=\"macro\")\n",
    "                auc_scores.append(auc)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao treinar XGBoost: {e}\")\n",
    "\n",
    "    return (\n",
    "        np.mean(auc_scores) if auc_scores else 0.0\n",
    "    )  # Retornar 0 se todas as tentativas falharem\n",
    "\n",
    "\n",
    "def objective_catboost(trial, model_folds):\n",
    "    \"\"\"Função objetivo para CatBoost usando folds otimizados\"\"\"\n",
    "    param = {\n",
    "        \"iterations\": trial.suggest_int(\"iterations\", 50, 500),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3, log=True),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 4, 10),\n",
    "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1e-8, 10.0, log=True),\n",
    "        \"random_strength\": trial.suggest_float(\"random_strength\", 1e-8, 10.0, log=True),\n",
    "        \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0.0, 10.0),\n",
    "        \"grow_policy\": trial.suggest_categorical(\n",
    "            \"grow_policy\", [\"SymmetricTree\", \"Depthwise\", \"Lossguide\"]\n",
    "        ),\n",
    "        \"random_seed\": 42,\n",
    "        \"verbose\": False,\n",
    "    }\n",
    "\n",
    "    # Avaliação usando os folds otimizados\n",
    "    auc_scores = []\n",
    "    for X_train, X_test, y_train, y_test in model_folds:\n",
    "        try:\n",
    "            model = CatBoostClassifier(**param)\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Calcular AUC\n",
    "            if hasattr(model, \"predict_proba\"):\n",
    "                y_prob = model.predict_proba(X_test)\n",
    "                auc = roc_auc_score(y_test, y_prob, multi_class=\"ovr\", average=\"macro\")\n",
    "                auc_scores.append(auc)\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao treinar CatBoost: {e}\")\n",
    "\n",
    "    return (\n",
    "        np.mean(auc_scores) if auc_scores else 0.0\n",
    "    )  # Retornar 0 se todas as tentativas falharem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FX3rGlQFxWRF"
   },
   "source": [
    "## Funções Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EHsh27ktOFu2"
   },
   "outputs": [],
   "source": [
    "def optimize_models_with_optimized_folds(optimized_folds, n_trials=50, timeout=None):\n",
    "    \"\"\"\n",
    "    Otimiza os hiperparâmetros para todos os modelos usando os folds otimizados\n",
    "\n",
    "    Args:\n",
    "        optimized_folds: Dicionário com folds otimizados por modelo\n",
    "        n_trials: Número de tentativas para cada modelo\n",
    "        timeout: Tempo máximo em segundos para cada modelo (None = sem limite)\n",
    "\n",
    "    Returns:\n",
    "        dict: Dicionário com os melhores parâmetros para cada modelo\n",
    "    \"\"\"\n",
    "    # Definir os modelos e suas respectivas funções objetivo\n",
    "    objective_funcs = {\n",
    "        \"Decision Trees\": objective_dt,\n",
    "        \"Gradient Tree Boosting\": objective_gb,\n",
    "        \"k-Nearest Neighbors\": objective_knn,\n",
    "        \"LightGBM\": objective_lgbm,\n",
    "        \"Multinomial Logistic Regression\": objective_lr,\n",
    "        \"Naive Bayes\": objective_nb,\n",
    "        \"Random Forests\": objective_rf,\n",
    "        \"Support Vector Machines\": objective_svm,\n",
    "        \"XGBoost\": objective_xgb,\n",
    "        \"CatBoost\": objective_catboost,\n",
    "    }\n",
    "\n",
    "    # Verificar se os nomes dos modelos coincidem com os das funções objetivo\n",
    "    model_names = set(optimized_folds.keys())\n",
    "    objective_names = set(objective_funcs.keys())\n",
    "    missing_models = model_names - objective_names\n",
    "\n",
    "    if missing_models:\n",
    "        print(f\"Aviso: Modelos sem função objetivo correspondente: {missing_models}\")\n",
    "\n",
    "    # Dicionários para armazenar resultados\n",
    "    best_params = {}\n",
    "    best_scores = {}\n",
    "    optimization_times = {}\n",
    "\n",
    "    # Para cada modelo, criar e otimizar um estudo\n",
    "    for model_name, model_data in tqdm(\n",
    "        optimized_folds.items(), desc=\"Otimizando modelos\"\n",
    "    ):\n",
    "        if model_name not in objective_funcs:\n",
    "            print(f\"Pulando {model_name} - função objetivo não disponível\")\n",
    "            continue\n",
    "\n",
    "        print(\n",
    "            f\"\\nOtimizando hiperparâmetros para {model_name} - dataset {model_data['dataset_type']}...\"\n",
    "        )\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Obter os folds otimizados para este modelo\n",
    "        model_folds = model_data[\"folds\"]\n",
    "\n",
    "        # Criar estudo Optuna\n",
    "        study = optuna.create_study(\n",
    "            direction=\"maximize\", study_name=f\"{model_name} Optimization\"\n",
    "        )\n",
    "\n",
    "        # Criar closure para a função objetivo com os folds otimizados\n",
    "        objective_func = objective_funcs[model_name]\n",
    "        obj_func = lambda trial: objective_func(trial, model_folds)\n",
    "\n",
    "        # Otimizar com limite de tempo\n",
    "        try:\n",
    "            study.optimize(obj_func, n_trials=n_trials, timeout=timeout)\n",
    "\n",
    "            # Armazenar os melhores parâmetros e score\n",
    "            best_params[model_name] = study.best_params\n",
    "            best_scores[model_name] = study.best_value\n",
    "\n",
    "            end_time = time.time()\n",
    "            optimization_times[model_name] = end_time - start_time\n",
    "\n",
    "            print(f\"Melhor score para {model_name}: {study.best_value:.4f}\")\n",
    "            print(f\"Melhores parâmetros para {model_name}: {study.best_params}\")\n",
    "            print(f\"Tempo de otimização: {optimization_times[model_name]:.2f} segundos\")\n",
    "\n",
    "            # Salvar o estudo\n",
    "            os.makedirs(\"optuna_studies\", exist_ok=True)\n",
    "            joblib.dump(\n",
    "                study,\n",
    "                f\"optuna_studies/{model_name.replace(' ', '_').lower()}_study.pkl\",\n",
    "            )\n",
    "\n",
    "            # Visualizações\n",
    "            try:\n",
    "                os.makedirs(\"optuna_plots\", exist_ok=True)\n",
    "                # Histórico de otimização\n",
    "                fig = plot_optimization_history(study)\n",
    "                fig.write_image(\n",
    "                    f\"optuna_plots/{model_name.replace(' ', '_').lower()}_optimization_history.png\"\n",
    "                )\n",
    "\n",
    "                # Importância dos parâmetros\n",
    "                fig = plot_param_importances(study)\n",
    "                fig.write_image(\n",
    "                    f\"optuna_plots/{model_name.replace(' ', '_').lower()}_param_importances.png\"\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Aviso: Erro ao criar visualizações para {model_name}: {e}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Erro durante a otimização de {model_name}: {e}\")\n",
    "            best_params[model_name] = None\n",
    "            best_scores[model_name] = float(\"nan\")\n",
    "            optimization_times[model_name] = float(\"nan\")\n",
    "\n",
    "    # Exibir resumo de resultados\n",
    "    print(f\"\\n=== Resumo dos Resultados de Otimização ===\")\n",
    "    results_df = pd.DataFrame(\n",
    "        {\n",
    "            \"Modelo\": list(best_params.keys()),\n",
    "            \"Melhor AUC\": [\n",
    "                best_scores.get(model, float(\"nan\")) for model in best_params\n",
    "            ],\n",
    "            \"Tempo (s)\": [\n",
    "                optimization_times.get(model, float(\"nan\")) for model in best_params\n",
    "            ],\n",
    "            \"Dataset\": [\n",
    "                optimized_folds[model][\"dataset_type\"] for model in best_params\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Ordenar por melhor score\n",
    "    results_df = results_df.sort_values(\"Melhor AUC\", ascending=False).reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "    print(results_df)\n",
    "\n",
    "    # Salvar hiperparâmetros em um arquivo TXT\n",
    "    save_hyperparameters_to_txt(best_params, best_scores, optimized_folds)\n",
    "\n",
    "    # Criar gráfico de barras para comparar modelos\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(results_df)))\n",
    "    ax = sns.barplot(x=\"Modelo\", y=\"Melhor AUC\", data=results_df, palette=colors)\n",
    "    plt.title(\"Comparação de AUC para Modelos Otimizados\", fontsize=16)\n",
    "    plt.ylabel(\"AUC Score\", fontsize=14)\n",
    "    plt.xlabel(\"Modelo\", fontsize=14)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.ylim(0.5, 1.0)\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    # Adicionar valores\n",
    "    for i, v in enumerate(results_df[\"Melhor AUC\"]):\n",
    "        ax.text(i, v + 0.01, f\"{v:.4f}\", ha=\"center\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"model_comparison_optimized.png\")\n",
    "    plt.show()\n",
    "\n",
    "    return best_params, best_scores\n",
    "\n",
    "\n",
    "def save_hyperparameters_to_txt(best_params, best_scores, optimized_folds):\n",
    "    \"\"\"\n",
    "    Salva os melhores hiperparâmetros para cada modelo em um arquivo TXT\n",
    "\n",
    "    Args:\n",
    "        best_params: Dicionário com os melhores hiperparâmetros para cada modelo\n",
    "        best_scores: Dicionário com os melhores scores para cada modelo\n",
    "        optimized_folds: Dicionário com informações sobre os folds otimizados\n",
    "    \"\"\"\n",
    "    with open(\"best_hyperparameters.txt\", \"w\") as f:\n",
    "        f.write(\"MELHORES HIPERPARÂMETROS PARA CADA MODELO\\n\")\n",
    "        f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "\n",
    "        # Ordenar modelos por AUC score\n",
    "        sorted_models = sorted(\n",
    "            best_params.keys(),\n",
    "            key=lambda model: best_scores.get(model, 0),\n",
    "            reverse=True,\n",
    "        )\n",
    "\n",
    "        for model_name in sorted_models:\n",
    "            params = best_params.get(model_name)\n",
    "            score = best_scores.get(model_name, float(\"nan\"))\n",
    "            dataset_type = optimized_folds[model_name][\"dataset_type\"]\n",
    "            features = optimized_folds[model_name][\"features\"]\n",
    "\n",
    "            f.write(f\"Modelo: {model_name}\\n\")\n",
    "            f.write(\"-\" * 80 + \"\\n\")\n",
    "            f.write(f\"Dataset: {dataset_type}\\n\")\n",
    "            f.write(f\"Melhor AUC: {score:.4f}\\n\")\n",
    "            f.write(f\"Número de Features: {len(features)}\\n\")\n",
    "            f.write(f\"Features: {', '.join(features)}\\n\\n\")\n",
    "            f.write(\"Hiperparâmetros:\\n\")\n",
    "\n",
    "            if params:\n",
    "                for param_name, param_value in params.items():\n",
    "                    f.write(f\"  {param_name}: {param_value}\\n\")\n",
    "            else:\n",
    "                f.write(\n",
    "                    \"  Não foi possível otimizar os hiperparâmetros para este modelo.\\n\"\n",
    "                )\n",
    "\n",
    "            f.write(\"\\n\" + \"=\" * 80 + \"\\n\\n\")\n",
    "\n",
    "    print(f\"Melhores hiperparâmetros salvos em 'best_hyperparameters.txt'\")\n",
    "\n",
    "\n",
    "def train_and_evaluate_models_with_best_params(optimized_folds, best_params):\n",
    "    \"\"\"\n",
    "    Treina e avalia modelos com os melhores hiperparâmetros usando os folds otimizados\n",
    "\n",
    "    Args:\n",
    "        optimized_folds: Dicionário com folds otimizados por modelo\n",
    "        best_params: Dicionário com os melhores hiperparâmetros para cada modelo\n",
    "\n",
    "    Returns:\n",
    "        dict: Dicionário com resultados detalhados\n",
    "        DataFrame: DataFrame com resultados resumidos\n",
    "    \"\"\"\n",
    "    # Definir os construtores de modelos\n",
    "    model_constructors = {\n",
    "        \"Decision Trees\": DecisionTreeClassifier,\n",
    "        \"Gradient Tree Boosting\": GradientBoostingClassifier,\n",
    "        \"k-Nearest Neighbors\": KNeighborsClassifier,\n",
    "        \"LightGBM\": LGBMClassifier,\n",
    "        \"Multinomial Logistic Regression\": LogisticRegression,\n",
    "        \"Naive Bayes\": GaussianNB,\n",
    "        \"Random Forests\": RandomForestClassifier,\n",
    "        \"Support Vector Machines\": SVC,\n",
    "        \"XGBoost\": XGBClassifier,\n",
    "        \"CatBoost\": CatBoostClassifier,\n",
    "    }\n",
    "\n",
    "    # Adicionar parâmetros fixos para alguns modelos\n",
    "    fixed_params = {\n",
    "        \"Multinomial Logistic Regression\": {\n",
    "            \"max_iter\": 2000,\n",
    "            \"multi_class\": \"multinomial\",\n",
    "        },\n",
    "        \"Support Vector Machines\": {\"probability\": True},\n",
    "    }\n",
    "\n",
    "    # Dicionário para armazenar resultados\n",
    "    results = defaultdict(dict)\n",
    "\n",
    "    # Treinar e avaliar cada modelo\n",
    "    print(\"\\n=== Treinamento e Avaliação de Modelos Otimizados ===\")\n",
    "\n",
    "    for model_name, constructor in tqdm(\n",
    "        model_constructors.items(), desc=\"Treinando modelos\"\n",
    "    ):\n",
    "        if model_name not in optimized_folds or best_params.get(model_name) is None:\n",
    "            print(f\"Pulando {model_name} - dados ou parâmetros não disponíveis\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\nTreinando e avaliando {model_name}...\")\n",
    "\n",
    "        # Obter parâmetros otimizados\n",
    "        params = best_params[model_name].copy()\n",
    "\n",
    "        # Adicionar parâmetros fixos, se necessário\n",
    "        if model_name in fixed_params:\n",
    "            params.update(fixed_params[model_name])\n",
    "\n",
    "        # Adicionar random_state para reprodutibilidade (se aplicável)\n",
    "        if model_name not in [\"k-Nearest Neighbors\", \"Naive Bayes\"]:\n",
    "            params[\"random_state\"] = 42\n",
    "\n",
    "        # Obter os folds otimizados para este modelo\n",
    "        model_folds = optimized_folds[model_name][\"folds\"]\n",
    "\n",
    "        # Métricas por fold\n",
    "        fold_metrics = []\n",
    "\n",
    "        # Avaliar em cada fold\n",
    "        for fold_idx, (X_train, X_test, y_train, y_test) in enumerate(model_folds):\n",
    "            print(f\"  Fold {fold_idx+1}/{len(model_folds)}\")\n",
    "\n",
    "            # Inicializar variáveis para evitar UnboundLocalError\n",
    "            model = None\n",
    "            f1_score_val = float(\"nan\")  # Substituição da acurácia pelo F1-score\n",
    "            auc = float(\"nan\")\n",
    "            conf_matrix = None\n",
    "            class_report = None\n",
    "\n",
    "            # Treinar modelo diretamente sem mapeamento de classes\n",
    "            try:\n",
    "                model = constructor(**params)\n",
    "                model.fit(X_train, y_train)\n",
    "\n",
    "                # Prever - tratamento especial para o CatBoost\n",
    "                if model_name == \"CatBoost\":\n",
    "                    try:\n",
    "                        # Tentar obter classes diretamente\n",
    "                        y_pred = model.predict(X_test)\n",
    "                        # Garantir que são valores escalares\n",
    "                        if isinstance(y_pred, np.ndarray) and y_pred.ndim > 1:\n",
    "                            y_pred = np.argmax(y_pred, axis=1)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Erro ao prever com CatBoost: {e}\")\n",
    "                        # Usar um método alternativo\n",
    "                        y_prob = model.predict_proba(X_test)\n",
    "                        y_pred = np.argmax(y_prob, axis=1)\n",
    "                else:\n",
    "                    # Para outros modelos\n",
    "                    y_pred = model.predict(X_test)\n",
    "\n",
    "                # Calcular AUC score\n",
    "                if hasattr(model, \"predict_proba\"):\n",
    "                    y_prob = model.predict_proba(X_test)\n",
    "                    auc = roc_auc_score(\n",
    "                        y_test, y_prob, multi_class=\"ovr\", average=\"macro\"\n",
    "                    )\n",
    "                else:\n",
    "                    auc = float(\"nan\")\n",
    "\n",
    "                # Calcular métricas - usando F1-score ponderado em vez de acurácia\n",
    "                f1_score_val = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "                conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "                class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  Erro ao treinar/avaliar o modelo: {e}\")\n",
    "                # Variáveis já foram inicializadas com valores padrão\n",
    "\n",
    "            # Armazenar métricas deste fold\n",
    "            fold_metrics.append(\n",
    "                {\n",
    "                    \"fold_idx\": fold_idx,\n",
    "                    \"f1_score\": f1_score_val,  # Substituição da acurácia pelo F1-score\n",
    "                    \"auc\": auc,\n",
    "                    \"model\": model,  # Pode ser None se houver falha\n",
    "                    \"conf_matrix\": conf_matrix,\n",
    "                    \"class_report\": class_report,\n",
    "                }\n",
    "            )\n",
    "\n",
    "            # Exibir métricas formatadas corretamente\n",
    "            print(\n",
    "                f\"    F1-Score: {f'{f1_score_val:.4f}' if not np.isnan(f1_score_val) else 'N/A'}\"\n",
    "            )\n",
    "            print(f\"    AUC: {f'{auc:.4f}' if not np.isnan(auc) else 'N/A'}\")\n",
    "\n",
    "        # Calcular médias (ignorando NaN)\n",
    "        valid_f1_scores = [\n",
    "            m[\"f1_score\"] for m in fold_metrics if not np.isnan(m[\"f1_score\"])\n",
    "        ]\n",
    "        valid_aucs = [m[\"auc\"] for m in fold_metrics if not np.isnan(m[\"auc\"])]\n",
    "\n",
    "        mean_f1_score = np.mean(valid_f1_scores) if valid_f1_scores else float(\"nan\")\n",
    "        mean_auc = np.mean(valid_aucs) if valid_aucs else float(\"nan\")\n",
    "\n",
    "        # Determinar o melhor fold com base no AUC (se houver)\n",
    "        if valid_aucs:\n",
    "            best_fold_idx = np.argmax(\n",
    "                [m[\"auc\"] if not np.isnan(m[\"auc\"]) else -np.inf for m in fold_metrics]\n",
    "            )\n",
    "            best_model = fold_metrics[best_fold_idx][\"model\"]\n",
    "        else:\n",
    "            best_fold_idx = 0\n",
    "            best_model = None\n",
    "\n",
    "        # Armazenar resultados deste modelo\n",
    "        results[model_name] = {\n",
    "            \"fold_metrics\": fold_metrics,\n",
    "            \"mean_f1_score\": mean_f1_score,  # Substituição da acurácia pelo F1-score\n",
    "            \"mean_auc\": mean_auc,\n",
    "            \"dataset_type\": optimized_folds[model_name][\"dataset_type\"],\n",
    "            \"best_fold_idx\": best_fold_idx,\n",
    "            \"best_model\": best_model,\n",
    "        }\n",
    "\n",
    "        print(\n",
    "            f\"  Média de F1-Score: {f'{mean_f1_score:.4f}' if not np.isnan(mean_f1_score) else 'N/A'}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"  Média de AUC: {f'{mean_auc:.4f}' if not np.isnan(mean_auc) else 'N/A'}\"\n",
    "        )\n",
    "\n",
    "    # Criar DataFrame com resultados resumidos\n",
    "    summary_data = []\n",
    "    for model_name, model_results in results.items():\n",
    "        summary_data.append(\n",
    "            {\n",
    "                \"Modelo\": model_name,\n",
    "                \"Dataset\": model_results[\"dataset_type\"],\n",
    "                \"F1-Score\": model_results[\n",
    "                    \"mean_f1_score\"\n",
    "                ],  # Substituição da acurácia pelo F1-score\n",
    "                \"AUC\": model_results[\"mean_auc\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    results_df = pd.DataFrame(summary_data)\n",
    "    results_df = results_df.sort_values(\"AUC\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Exibir tabela de resultados\n",
    "    print(\"\\n=== Resultados Finais ===\")\n",
    "    print(results_df)\n",
    "\n",
    "    # Plotar resultados\n",
    "    plt.figure(figsize=(14, 10))\n",
    "\n",
    "    # Subplot para F1-Score\n",
    "    plt.subplot(2, 1, 1)\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(results_df)))\n",
    "    ax1 = sns.barplot(x=\"Modelo\", y=\"F1-Score\", data=results_df, palette=colors)\n",
    "    plt.title(\"Comparação de F1-Score para Modelos Otimizados\", fontsize=16)\n",
    "    plt.ylabel(\"F1-Score\", fontsize=14)\n",
    "    plt.ylim(0.5, 1.0)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    # Adicionar valores\n",
    "    for i, v in enumerate(results_df[\"F1-Score\"]):\n",
    "        if not np.isnan(v):\n",
    "            ax1.text(i, v + 0.01, f\"{v:.4f}\", ha=\"center\")\n",
    "\n",
    "    # Subplot para AUC\n",
    "    plt.subplot(2, 1, 2)\n",
    "    ax2 = sns.barplot(x=\"Modelo\", y=\"AUC\", data=results_df, palette=colors)\n",
    "    plt.title(\"Comparação de AUC para Modelos Otimizados\", fontsize=16)\n",
    "    plt.ylabel(\"AUC Score\", fontsize=14)\n",
    "    plt.xlabel(\"Modelo\", fontsize=14)\n",
    "    plt.ylim(0.5, 1.0)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    # Adicionar valores\n",
    "    for i, v in enumerate(results_df[\"AUC\"]):\n",
    "        if not np.isnan(v):\n",
    "            ax2.text(i, v + 0.01, f\"{v:.4f}\", ha=\"center\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"final_model_evaluation.png\")\n",
    "    plt.show()\n",
    "\n",
    "    # Salvar o melhor modelo geral\n",
    "    valid_models = results_df[~results_df[\"AUC\"].isna()]\n",
    "    if not valid_models.empty:\n",
    "        best_model_idx = valid_models[\"AUC\"].idxmax()\n",
    "        best_model_row = results_df.iloc[best_model_idx]\n",
    "        best_model_name = best_model_row[\"Modelo\"]\n",
    "        best_dataset_name = best_model_row[\"Dataset\"]\n",
    "\n",
    "        best_model = results[best_model_name][\"best_model\"]\n",
    "\n",
    "        # Salvar o modelo\n",
    "        if best_model is not None:\n",
    "            os.makedirs(\"models\", exist_ok=True)\n",
    "            joblib.dump(\n",
    "                best_model,\n",
    "                f\"models/best_model_{best_model_name.replace(' ', '_').lower()}.pkl\",\n",
    "            )\n",
    "            print(f\"\\nMelhor modelo: {best_model_name} (Dataset: {best_dataset_name})\")\n",
    "            print(f\"AUC: {best_model_row['AUC']:.4f}\")\n",
    "            print(\n",
    "                f\"F1-Score: {best_model_row['F1-Score']:.4f}\"\n",
    "            )  # Ajustado para exibir F1-Score\n",
    "            print(\n",
    "                f\"Modelo salvo como 'models/best_model_{best_model_name.replace(' ', '_').lower()}.pkl'\"\n",
    "            )\n",
    "\n",
    "            # Se for um modelo baseado em árvore, mostrar a importância das features\n",
    "            if hasattr(best_model, \"feature_importances_\"):\n",
    "                features = optimized_folds[best_model_name][\"features\"]\n",
    "                importances = pd.DataFrame(\n",
    "                    {\"Feature\": features, \"Importance\": best_model.feature_importances_}\n",
    "                ).sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                sns.barplot(x=\"Importance\", y=\"Feature\", data=importances)\n",
    "                plt.title(\n",
    "                    f\"Importância das Features para {best_model_name}\", fontsize=14\n",
    "                )\n",
    "                plt.tight_layout()\n",
    "                plt.savefig(\"best_model_feature_importance.png\")\n",
    "                plt.show()\n",
    "\n",
    "                print(\"\\nImportância das Features:\")\n",
    "                print(importances)\n",
    "    else:\n",
    "        print(\"\\nNenhum modelo válido encontrado.\")\n",
    "\n",
    "    return results, results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S-I8dxzCxeID"
   },
   "outputs": [],
   "source": [
    "def buscar_hiperparametros():\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(\"===== INICIANDO O PROCESSO DE OTIMIZAÇÃO COM FOLDS OTIMIZADOS =====\")\n",
    "\n",
    "    # 1. Criar folds otimizados para cada modelo\n",
    "    print(\"\\nCriando folds otimizados para cada modelo...\")\n",
    "    optimized_folds = create_optimized_model_folds(\n",
    "        original_folds_data, smote_folds_data\n",
    "    )\n",
    "\n",
    "    # 2. Otimizar hiperparâmetros para cada modelo usando os folds otimizados\n",
    "    print(\"\\nOtimizando hiperparâmetros para cada modelo...\")\n",
    "    best_params, best_scores = optimize_models_with_optimized_folds(\n",
    "        optimized_folds,\n",
    "        n_trials=30,  # Reduzido para exemplo\n",
    "        timeout=600,  # 10 minutos por modelo\n",
    "    )\n",
    "\n",
    "    # 3. Treinar e avaliar modelos com os melhores hiperparâmetros\n",
    "    print(\"\\nTreinando e avaliando modelos com os melhores hiperparâmetros...\")\n",
    "    results, results_df = train_and_evaluate_models_with_best_params(\n",
    "        optimized_folds, best_params\n",
    "    )\n",
    "\n",
    "    # Exibir tempo de execução\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "    hours, remainder = divmod(total_time, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "\n",
    "    print(\"\\n===== PROCESSO CONCLUÍDO =====\")\n",
    "    print(f\"Tempo total de execução: {int(hours)}h {int(minutes)}m {int(seconds)}s\")\n",
    "\n",
    "    return optimized_folds, best_params, results, results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execução da Busca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_OuikJUpxx4G",
    "outputId": "69562335-8564-4fd8-d87b-250087454a41"
   },
   "outputs": [],
   "source": [
    "optimized_folds, best_params, results, resultds_df = buscar_hiperparametros()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Avaliação de Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 - Comparativo dos Modelos\n",
    "Nesta subseção calcularemos treinaremos os modelos com os melhores datasets e os melhores hiperparametros encontrados até aqui e faremos um gráfico comparativo das suas AUC_ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models_performance():\n",
    "    \"\"\"\n",
    "    Compara o desempenho dos modelos treinados com os melhores hiperparâmetros\n",
    "    em termos de AUC-ROC e F1-score ponderado.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"5.1 Comparativo dos Modelos\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Vamos extrair os modelos e seus resultados\n",
    "    models_summary = []\n",
    "\n",
    "    for model_name, model_results in results.items():\n",
    "        best_fold_idx = model_results[\"best_fold_idx\"]\n",
    "        fold_metrics = model_results[\"fold_metrics\"][best_fold_idx]\n",
    "\n",
    "        models_summary.append(\n",
    "            {\n",
    "                \"Modelo\": model_name,\n",
    "                \"AUC\": model_results[\"mean_auc\"],\n",
    "                \"F1-Score\": model_results[\n",
    "                    \"mean_f1_score\"\n",
    "                ],  # Substituído Acurácia por F1-Score\n",
    "                \"Dataset\": model_results[\"dataset_type\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    # Criar DataFrame com os resultados resumidos\n",
    "    summary_df = pd.DataFrame(models_summary)\n",
    "    summary_df = summary_df.sort_values(\"AUC\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Exibir resultados\n",
    "    print(\"\\nResumo de desempenho dos modelos ordenados por AUC:\")\n",
    "    print(summary_df)\n",
    "\n",
    "    # Criar gráfico de barras para comparação visual\n",
    "    plt.figure(figsize=(14, 10))\n",
    "\n",
    "    # Gráfico para AUC\n",
    "    plt.subplot(2, 1, 1)\n",
    "    sns.barplot(x=\"Modelo\", y=\"AUC\", data=summary_df, palette=\"viridis\")\n",
    "    plt.title(\"Comparação de AUC dos Modelos Otimizados\", fontsize=16)\n",
    "    plt.ylim(0.5, 1.0)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    # Adicionar valores\n",
    "    for i, v in enumerate(summary_df[\"AUC\"]):\n",
    "        plt.text(i, v + 0.01, f\"{v:.4f}\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "    # Gráfico para F1-Score (anteriormente Acurácia)\n",
    "    plt.subplot(2, 1, 2)\n",
    "    sns.barplot(x=\"Modelo\", y=\"F1-Score\", data=summary_df, palette=\"viridis\")\n",
    "    plt.title(\"Comparação de F1-Score Ponderado dos Modelos Otimizados\", fontsize=16)\n",
    "    plt.ylim(0.5, 1.0)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    # Adicionar valores\n",
    "    for i, v in enumerate(summary_df[\"F1-Score\"]):\n",
    "        plt.text(i, v + 0.01, f\"{v:.4f}\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"models_performance_comparison.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SEÇÃO 5: AVALIAÇÃO DE MODELOS\")\n",
    "print(\"=\" * 80)\n",
    "comparison_df = compare_models_performance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 - Comparativo dos Desempenhos por Decil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_decile_plot(optimized_folds, best_params, results, save_path=\"decile_plots\"):\n",
    "    \"\"\"\n",
    "    Cria gráficos de análise por decil para os modelos treinados.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"5.2 Análise de Desempenho por Decil\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Criar diretório para salvar os gráficos\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    # Para cada modelo\n",
    "    for model_name, model_results in results.items():\n",
    "        print(f\"\\nAnalisando modelo: {model_name}\")\n",
    "\n",
    "        # Obter o melhor modelo deste tipo\n",
    "        best_model = model_results.get(\"best_model\")\n",
    "        if best_model is None:\n",
    "            print(f\"  Modelo {model_name} não tem um modelo válido disponível.\")\n",
    "            continue\n",
    "\n",
    "        # Obter o melhor fold para análise\n",
    "        best_fold_idx = model_results.get(\"best_fold_idx\", 0)\n",
    "        try:\n",
    "            X_test = optimized_folds[model_name][\"folds\"][best_fold_idx][1]\n",
    "            y_test = optimized_folds[model_name][\"folds\"][best_fold_idx][3]\n",
    "        except (KeyError, IndexError) as e:\n",
    "            print(f\"  Erro ao acessar dados do fold para {model_name}: {e}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # SOLUÇÃO: Trabalhar com os índices de linha diretamente\n",
    "            # Criar um array para rastrear o índice original\n",
    "            row_indices = np.arange(len(X_test))\n",
    "\n",
    "            # Obter probabilidades ou decisões do modelo\n",
    "            if hasattr(best_model, \"predict_proba\"):\n",
    "                probs = best_model.predict_proba(X_test)\n",
    "                if probs.shape[1] > 2:  # Multiclasse\n",
    "                    probabilities = probs.max(axis=1)\n",
    "                else:  # Binário\n",
    "                    probabilities = probs[:, 1]\n",
    "            else:\n",
    "                # Se não tem probabilidade, usar decisão\n",
    "                predictions = best_model.predict(X_test)\n",
    "                probabilities = predictions\n",
    "\n",
    "            # Preparar dados para análise\n",
    "            decile_data = {\n",
    "                \"row_idx\": row_indices,  # Para rastrear o índice original\n",
    "                \"probability\": probabilities,\n",
    "                \"true_class\": y_test.values if hasattr(y_test, \"values\") else y_test,\n",
    "            }\n",
    "\n",
    "            # DataFrame para análise\n",
    "            df = pd.DataFrame(decile_data)\n",
    "\n",
    "            # Ordenar por probabilidade\n",
    "            df = df.sort_values(\"probability\", ascending=False)\n",
    "\n",
    "            # Atribuir decil com base na posição\n",
    "            n_samples = len(df)\n",
    "            df[\"decile\"] = np.floor(np.arange(n_samples) / n_samples * 10).astype(int)\n",
    "\n",
    "            # DataFrame para armazenar métricas por decil\n",
    "            decile_metrics = pd.DataFrame(index=range(10))\n",
    "            decile_metrics[\"count\"] = 0\n",
    "            decile_metrics[\"f1_score\"] = 0.0\n",
    "\n",
    "            # Calcular métricas por decil\n",
    "            for decile in range(10):\n",
    "                decile_df = df[df[\"decile\"] == decile]\n",
    "                if len(decile_df) > 0:\n",
    "                    # Obter previsões para este decil usando os índices originais das linhas\n",
    "                    # CORREÇÃO: Usar os índices de linha rastreados\n",
    "                    decile_row_indices = decile_df[\"row_idx\"].values\n",
    "                    decile_X = X_test.iloc[decile_row_indices]\n",
    "                    decile_y = decile_df[\"true_class\"].values\n",
    "\n",
    "                    # Calcular previsões\n",
    "                    if hasattr(best_model, \"predict_proba\"):\n",
    "                        if probs.shape[1] > 2:  # Multiclasse\n",
    "                            decile_preds = best_model.predict(decile_X)\n",
    "                        else:  # Binário\n",
    "                            decile_preds = (decile_df[\"probability\"] > 0.5).astype(int)\n",
    "                    else:\n",
    "                        decile_preds = decile_df[\"probability\"]\n",
    "\n",
    "                    # Calcular F1-score para este decil\n",
    "                    try:\n",
    "                        f1 = f1_score(decile_y, decile_preds, average=\"weighted\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"    Erro ao calcular F1-score para decil {decile}: {e}\")\n",
    "                        f1 = 0.0\n",
    "\n",
    "                    decile_metrics.loc[decile, \"count\"] = len(decile_df)\n",
    "                    decile_metrics.loc[decile, \"f1_score\"] = f1\n",
    "\n",
    "            # Calcular proporção por decil\n",
    "            decile_metrics[\"proportion\"] = (\n",
    "                decile_metrics[\"count\"] / decile_metrics[\"count\"].sum()\n",
    "            )\n",
    "\n",
    "            # Criar gráfico\n",
    "            fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "            # Barras para proporção (representatividade)\n",
    "            ax1.bar(\n",
    "                decile_metrics.index,\n",
    "                decile_metrics[\"proportion\"] * 100,\n",
    "                color=\"navy\",\n",
    "                alpha=0.8,\n",
    "                label=\"Representatividade (%)\",\n",
    "            )\n",
    "            ax1.set_xlabel(\"Decil da população\")\n",
    "            ax1.set_ylabel(\"Representatividade (%)\")\n",
    "            ax1.set_ylim(\n",
    "                0, decile_metrics[\"proportion\"].max() * 120\n",
    "            )  # 20% a mais para espaço\n",
    "\n",
    "            # Linha para F1-score\n",
    "            ax2 = ax1.twinx()\n",
    "            ax2.plot(\n",
    "                decile_metrics.index,\n",
    "                decile_metrics[\"f1_score\"] * 100,\n",
    "                color=\"red\",\n",
    "                marker=\"o\",\n",
    "                linewidth=2,\n",
    "                label=\"F1-score ponderado (%)\",\n",
    "            )\n",
    "            ax2.set_ylabel(\"F1-score ponderado (%)\")\n",
    "            ax2.set_ylim(0, 100)\n",
    "\n",
    "            # Ajustes finais\n",
    "            plt.title(f\"Análise por Decil - {model_name}\", fontsize=14)\n",
    "            lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "            lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "            ax1.legend(lines1 + lines2, labels1 + labels2, loc=\"lower right\")\n",
    "            plt.xticks(range(10))\n",
    "            plt.grid(axis=\"y\", alpha=0.3)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(\n",
    "                f\"{save_path}/{model_name.replace(' ', '_')}_decile_plot.png\", dpi=300\n",
    "            )\n",
    "            plt.close()\n",
    "\n",
    "            print(\n",
    "                f\"  Gráfico de análise por decil criado com sucesso para {model_name}\"\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Erro ao criar análise por decil para {model_name}: {e}\")\n",
    "            import traceback\n",
    "\n",
    "            traceback.print_exc()\n",
    "\n",
    "    print(f\"\\nAnálise por decil concluída. Gráficos salvos em '{save_path}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_decile_plot(optimized_folds, best_params, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 - Diferenciação dos Modelos\n",
    "Nesta subseção Usaremos a metodoogia do Demsar para testar quais modelos são diferentes entre si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_statistical_differences(summary_df):\n",
    "    \"\"\"\n",
    "    Aplica os testes de Friedman e Nemenyi conforme recomendado por Demšar (2006)\n",
    "    para identificar diferenças estatisticamente significativas entre os classificadores.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"5.2 Diferenciação dos Modelos (Testes Estatísticos)\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    # Extrair nomes dos modelos e suas métricas\n",
    "    model_names = summary_df[\"Modelo\"].tolist()\n",
    "    auc_values = summary_df[\"AUC\"].tolist()\n",
    "\n",
    "    # Para o teste de Friedman, precisaríamos das performances em cada fold\n",
    "    # Vamos construir uma matriz com modelos nas colunas e folds nas linhas\n",
    "\n",
    "    # Primeiro, determinar o número de folds (assumindo que todos os modelos têm mesmo número)\n",
    "    n_folds = len(results[model_names[0]][\"fold_metrics\"])\n",
    "\n",
    "    # Construir matriz de performace para o teste de Friedman\n",
    "    performance_matrix = np.zeros((n_folds, len(model_names)))\n",
    "\n",
    "    for j, model_name in enumerate(model_names):\n",
    "        for i in range(n_folds):\n",
    "            performance_matrix[i, j] = results[model_name][\"fold_metrics\"][i][\"auc\"]\n",
    "\n",
    "    # Convertendo para DataFrame para melhor visualização\n",
    "    performance_df = pd.DataFrame(performance_matrix, columns=model_names)\n",
    "\n",
    "    print(\"\\nMatriz de Performance (AUC) por fold e modelo:\")\n",
    "    print(performance_df)\n",
    "\n",
    "    # 1. Teste de Friedman\n",
    "    # O teste de Friedman verifica se há diferenças significativas entre os modelos\n",
    "\n",
    "    # Realizar o ranking por linha (fold)\n",
    "    ranks = np.zeros_like(performance_matrix)\n",
    "    for i in range(n_folds):\n",
    "        ranks[i, :] = stats.rankdata(\n",
    "            -performance_matrix[i, :]\n",
    "        )  # Negativo para ordenar decrescente\n",
    "\n",
    "    # Média dos ranks por modelo\n",
    "    mean_ranks = np.mean(ranks, axis=0)\n",
    "\n",
    "    # DataFrame para melhor visualização\n",
    "    rank_df = pd.DataFrame(\n",
    "        {\"Modelo\": model_names, \"Rank Médio\": mean_ranks}\n",
    "    ).sort_values(\"Rank Médio\")\n",
    "\n",
    "    print(\"\\nRanking médio dos modelos (menor é melhor):\")\n",
    "    print(rank_df)\n",
    "\n",
    "    # Estatística do teste de Friedman\n",
    "    k = len(model_names)  # número de modelos\n",
    "    n = n_folds  # número de folds/datasets\n",
    "\n",
    "    # Cálculo do Chi-quadrado de Friedman\n",
    "    chi2 = 12 * n / (k * (k + 1)) * (np.sum(mean_ranks**2) - k * (k + 1) ** 2 / 4)\n",
    "\n",
    "    # Correção por Iman e Davenport (1980)\n",
    "    ff = (n - 1) * chi2 / (n * (k - 1) - chi2)\n",
    "\n",
    "    # Valores críticos para F com (k-1) e (k-1)(n-1) graus de liberdade\n",
    "    df1 = k - 1\n",
    "    df2 = (k - 1) * (n - 1)\n",
    "    p_value = 1 - stats.f.cdf(ff, df1, df2)\n",
    "\n",
    "    print(f\"\\nTeste de Friedman com correção de Iman-Davenport:\")\n",
    "    print(f\"F({df1}, {df2}) = {ff:.4f}, p-value = {p_value:.4f}\")\n",
    "\n",
    "    alpha = 0.05\n",
    "    if p_value < alpha:\n",
    "        print(\n",
    "            f\"Há diferenças estatisticamente significativas entre os modelos (p < {alpha}).\"\n",
    "        )\n",
    "\n",
    "        # 2. Teste post-hoc de Nemenyi\n",
    "        # O teste de Nemenyi é usado após rejeitar H0 no teste de Friedman\n",
    "        # para identificar quais pares específicos de modelos são diferentes\n",
    "\n",
    "        # Diferença crítica para o teste de Nemenyi\n",
    "        q_alpha = get_nemenyi_critical_value(k, alpha)\n",
    "        cd = q_alpha * np.sqrt(k * (k + 1) / (6 * n))\n",
    "\n",
    "        print(f\"\\nTeste post-hoc de Nemenyi:\")\n",
    "        print(f\"Diferença Crítica (CD) = {cd:.4f}\")\n",
    "\n",
    "        # Matriz de diferenças entre pares de classificadores\n",
    "        diff_matrix = np.zeros((k, k))\n",
    "        p_matrix = np.zeros((k, k))\n",
    "\n",
    "        for i in range(k):\n",
    "            for j in range(i + 1, k):\n",
    "                diff = abs(mean_ranks[i] - mean_ranks[j])\n",
    "                diff_matrix[i, j] = diff\n",
    "                diff_matrix[j, i] = diff\n",
    "\n",
    "                # Verificar se a diferença é estatisticamente significativa\n",
    "                if diff > cd:\n",
    "                    p_matrix[i, j] = 1  # significativo\n",
    "                    p_matrix[j, i] = 1  # significativo\n",
    "\n",
    "        # Converter para DataFrames para visualização\n",
    "        diff_df = pd.DataFrame(diff_matrix, index=model_names, columns=model_names)\n",
    "        signif_df = pd.DataFrame(p_matrix, index=model_names, columns=model_names)\n",
    "\n",
    "        print(\"\\nMatriz de diferenças absolutas entre os ranks médios:\")\n",
    "        print(diff_df)\n",
    "\n",
    "        print(\"\\nMatriz de significância (1 = diferença significativa):\")\n",
    "        print(signif_df)\n",
    "\n",
    "        # Retornar dados necessários para visualização\n",
    "        return {\n",
    "            \"model_names\": model_names,\n",
    "            \"mean_ranks\": mean_ranks,\n",
    "            \"cd\": cd,\n",
    "            \"rank_df\": rank_df,\n",
    "            \"has_significant_diff\": True,\n",
    "            \"performance_df\": performance_df,\n",
    "        }\n",
    "    else:\n",
    "        print(\n",
    "            f\"Não há diferenças estatisticamente significativas entre os modelos (p > {alpha}).\"\n",
    "        )\n",
    "        return {\n",
    "            \"model_names\": model_names,\n",
    "            \"mean_ranks\": mean_ranks,\n",
    "            \"cd\": None,\n",
    "            \"rank_df\": rank_df,\n",
    "            \"has_significant_diff\": False,\n",
    "            \"performance_df\": performance_df,\n",
    "        }\n",
    "\n",
    "\n",
    "def get_nemenyi_critical_value(k, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Retorna o valor crítico q_alpha para o teste de Nemenyi baseado no número de classificadores.\n",
    "    Valores baseados na tabela do artigo de Demšar.\n",
    "    \"\"\"\n",
    "    # Valores críticos para q (baseados no artigo de Demšar para alpha = 0.05)\n",
    "    q_table = {\n",
    "        2: 1.960,\n",
    "        3: 2.343,\n",
    "        4: 2.569,\n",
    "        5: 2.728,\n",
    "        6: 2.850,\n",
    "        7: 2.949,\n",
    "        8: 3.031,\n",
    "        9: 3.102,\n",
    "        10: 3.164,\n",
    "    }\n",
    "\n",
    "    if k in q_table:\n",
    "        return q_table[k]\n",
    "    else:\n",
    "        # Para k > 10, uma aproximação pode ser usada\n",
    "        # Esta é uma simplificação; valores exatos devem ser consultados na literatura\n",
    "        return 3.164 + (k - 10) * 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_results = test_statistical_differences(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3 - Avaliação Final\n",
    "Dentre os modelos que são diferentes entre si, criaremos um gráfico comparativo com suas AUC_ROC. Caso dois modelos sejam equivalentes, ficará o modelo com melhor performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cd_diagram(stat_results):\n",
    "    \"\"\"\n",
    "    Cria um Diagrama CD (Critical Difference) conforme proposto por Demšar,\n",
    "    que visualiza os ranks médios dos classificadores e conecta aqueles que\n",
    "    não são estatisticamente diferentes.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"5.3 Avaliação Final\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    model_names = stat_results[\"model_names\"]\n",
    "    mean_ranks = stat_results[\"mean_ranks\"]\n",
    "    cd = stat_results[\"cd\"]\n",
    "\n",
    "    # Ordenar modelos por rank médio\n",
    "    model_ranks = list(zip(model_names, mean_ranks))\n",
    "    model_ranks.sort(key=lambda x: x[1])  # ordenar por rank\n",
    "\n",
    "    # Extrair nomes e ranks ordenados\n",
    "    sorted_names = [x[0] for x in model_ranks]\n",
    "    sorted_ranks = [x[1] for x in model_ranks]\n",
    "\n",
    "    # Criar figura\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Definir eixo do rank\n",
    "    ax = plt.gca()\n",
    "    ax.set_xlim(0.5, len(model_names) + 0.5)\n",
    "    ax.set_ylim(0, 2)\n",
    "\n",
    "    # Desenhar linha horizontal\n",
    "    plt.axhline(y=1, color=\"black\", linestyle=\"-\")\n",
    "\n",
    "    # Marcar posições dos classificadores\n",
    "    for i, (name, rank) in enumerate(zip(sorted_names, sorted_ranks)):\n",
    "        position = i + 1\n",
    "        plt.plot([position, position], [0.9, 1.1], \"k-\")\n",
    "        plt.text(position, 0.7, name, ha=\"center\", va=\"center\", rotation=45)\n",
    "        plt.text(position, 1.3, f\"{rank:.2f}\", ha=\"center\", va=\"center\")\n",
    "\n",
    "    # Se há diferença significativa, adicionar CD e conectar grupos não diferentes\n",
    "    if stat_results[\"has_significant_diff\"] and cd is not None:\n",
    "        plt.plot([1, 1 + cd], [0.4, 0.4], \"k-\")\n",
    "        plt.plot([1, 1], [0.4, 0.45], \"k-\")\n",
    "        plt.plot([1 + cd, 1 + cd], [0.4, 0.45], \"k-\")\n",
    "        plt.text(1 + cd / 2, 0.3, f\"CD = {cd:.2f}\", ha=\"center\", va=\"center\")\n",
    "\n",
    "        # Conectar classificadores que não são significativamente diferentes\n",
    "        # Esta é uma implementação simplificada; o algoritmo completo é mais complexo\n",
    "        for i, model_i in enumerate(sorted_names):\n",
    "            for j, model_j in enumerate(sorted_names):\n",
    "                if i < j:  # evitar comparações duplicadas\n",
    "                    idx_i = model_names.index(model_i)\n",
    "                    idx_j = model_names.index(model_j)\n",
    "\n",
    "                    if abs(mean_ranks[idx_i] - mean_ranks[idx_j]) <= cd:\n",
    "                        plt.plot([i + 1, j + 1], [1.7, 1.7], \"k-\")\n",
    "\n",
    "    plt.title(\"Diagrama de Diferença Crítica\", fontsize=16)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"critical_difference_diagram.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    # Resumo final dos resultados\n",
    "    print(\"\\nAvaliação Final dos Modelos:\")\n",
    "\n",
    "    if stat_results[\"has_significant_diff\"]:\n",
    "        print(f\"- Há diferenças estatisticamente significativas entre os modelos.\")\n",
    "        print(f\"- Diferença Crítica (CD): {cd:.4f}\")\n",
    "\n",
    "        # Identificar grupos de modelos estatisticamente equivalentes\n",
    "        groups = []\n",
    "        checked = set()\n",
    "\n",
    "        for i, model_i in enumerate(sorted_names):\n",
    "            if model_i in checked:\n",
    "                continue\n",
    "\n",
    "            group = [model_i]\n",
    "            checked.add(model_i)\n",
    "\n",
    "            for j, model_j in enumerate(sorted_names):\n",
    "                if model_j in checked or i == j:\n",
    "                    continue\n",
    "\n",
    "                idx_i = model_names.index(model_i)\n",
    "                idx_j = model_names.index(model_j)\n",
    "\n",
    "                if abs(mean_ranks[idx_i] - mean_ranks[idx_j]) <= cd:\n",
    "                    group.append(model_j)\n",
    "                    checked.add(model_j)\n",
    "\n",
    "            groups.append(group)\n",
    "\n",
    "        print(\"\\nGrupos de modelos estatisticamente equivalentes:\")\n",
    "        for i, group in enumerate(groups):\n",
    "            if len(group) > 1:\n",
    "                print(f\"  Grupo {i+1}: {', '.join(group)}\")\n",
    "            else:\n",
    "                print(f\"  Modelo isolado: {group[0]}\")\n",
    "\n",
    "        # Identificar o melhor modelo ou grupo de modelos\n",
    "        best_rank = min(sorted_ranks)\n",
    "        best_models = [\n",
    "            model\n",
    "            for model, rank in zip(sorted_names, sorted_ranks)\n",
    "            if rank == best_rank\n",
    "        ]\n",
    "\n",
    "        print(f\"\\nMelhor(es) modelo(s) com rank médio {best_rank:.2f}:\")\n",
    "        for model in best_models:\n",
    "            print(f\"  - {model}\")\n",
    "    else:\n",
    "        print(\"- Não há diferenças estatisticamente significativas entre os modelos.\")\n",
    "        print(\n",
    "            \"- Todos os modelos podem ser considerados equivalentes em termos de desempenho.\"\n",
    "        )\n",
    "\n",
    "    # Conclusões e recomendações finais\n",
    "    print(\"\\nConclusões e Recomendações:\")\n",
    "    if stat_results[\"has_significant_diff\"]:\n",
    "        best_model = sorted_names[0]\n",
    "        print(f\"- O modelo {best_model} apresentou o melhor desempenho geral.\")\n",
    "        print(\n",
    "            f\"- Recomenda-se utilizar o {best_model} para este problema, considerando:\"\n",
    "        )\n",
    "        print(f\"  * Melhor rank médio: {sorted_ranks[0]:.2f}\")\n",
    "        print(\n",
    "            f\"  * Diferença estatisticamente significativa em relação a alguns modelos.\"\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            f\"- Como não há diferenças significativas, recomenda-se considerar outros fatores além do desempenho:\"\n",
    "        )\n",
    "        print(f\"  * Tempo de treinamento e inferência\")\n",
    "        print(f\"  * Interpretabilidade do modelo\")\n",
    "        print(f\"  * Requisitos computacionais\")\n",
    "        print(f\"  * Facilidade de manutenção e atualização\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_cd_diagram(stat_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "tg-nJaHdDah",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
